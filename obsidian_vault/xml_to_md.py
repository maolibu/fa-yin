"""
CBETA XML â†’ Obsidian Markdown è½¬æ¢è„šæœ¬
ä½¿ç”¨ Bookcase åˆ†å·ç‰ˆ XMLï¼ˆä¸é˜…è¯»å™¨å…±ç”¨åŒä¸€ä»½æ•°æ®ï¼‰ï¼Œ
å°†æ¯éƒ¨ç»çš„æ‰€æœ‰å·åˆå¹¶ä¸ºä¸€ä¸ª Obsidian å‹å¥½çš„ Markdown æ–‡ä»¶ã€‚

ç”¨æ³•ï¼š
    python xml_to_md.py --sutra T08n0251         # è½¬æ¢å•éƒ¨ç»ï¼ˆå¿ƒç»ï¼‰
    python xml_to_md.py --canon T --limit 10      # è½¬æ¢å¤§æ­£è—å‰ 10 éƒ¨
    python xml_to_md.py --all --limit 50          # è½¬æ¢å…¨éƒ¨å‰ 50 éƒ¨

è¾“å‡ºç»“æ„ï¼š
    output/
    â”œâ”€â”€ é¦–é .md
    â”œâ”€â”€ ç›®éŒ„/éƒ¨é¡/ + ç›®éŒ„/ç¶“è—/
    â”œâ”€â”€ ç¶“æ–‡/{Canon}/{CanonVol}/{SutraId}_{Title}.md
    â””â”€â”€ ç­†è¨˜/

ä¾èµ–ï¼š
    - éœ€è¦ data/raw/cbeta/XML/ ä¸‹çš„åˆ†å· XML æ–‡ä»¶ï¼ˆBookcase ç‰ˆï¼‰
    - éœ€è¦ data/raw/cbeta/gaiji-CB/ ä¸‹çš„ç¼ºå­—æ•°æ®
    - éœ€è¦ data/raw/cbeta/bulei_nav.xhtmlï¼ˆéƒ¨ç±»åˆ†ç±»ï¼‰
"""

import argparse
import glob
import json
import os
import re
import sys
import time
import xml.etree.ElementTree as ET
from pathlib import Path

# ============================================================
# é…ç½®
# ============================================================
SCRIPT_DIR = Path(__file__).resolve().parent
PROJECT_ROOT = SCRIPT_DIR.parent  # 60_ready/

# Bookcase åˆ†å·ç‰ˆæ•°æ®ï¼ˆä¸é˜…è¯»å™¨å…±ç”¨ï¼‰
CBETA_BASE = PROJECT_ROOT / "data" / "raw" / "cbeta"
XML_BASE = CBETA_BASE / "XML"
GAIJI_JSON = PROJECT_ROOT.parent / "01_data_raw" / "cbeta_gaiji" / "cbeta_gaiji.json"
CANONS_JSON = PROJECT_ROOT.parent / "01_data_raw" / "cbeta_xml_p5" / "canons.json"
BULEI_NAV = CBETA_BASE / "bulei_nav.xhtml"
OUTPUT_DIR = SCRIPT_DIR / "output"

# XML å‘½åç©ºé—´
TEI_NS = "http://www.tei-c.org/ns/1.0"
CB_NS = "http://www.cbeta.org/ns/1.0"
XML_NS = "http://www.w3.org/XML/1998/namespace"

ET.register_namespace("", TEI_NS)
ET.register_namespace("cb", CB_NS)

# ============================================================
# Gaiji æ˜ å°„ï¼ˆå†…è”ï¼Œä¸ä¾èµ–å¤–éƒ¨æ¨¡å—ï¼‰
# ============================================================
_gaiji_map = None

def _load_gaiji():
    """åŠ è½½ç¼ºå­—æ˜ å°„è¡¨"""
    global _gaiji_map
    if _gaiji_map is not None:
        return _gaiji_map
    if not GAIJI_JSON.exists():
        print(f"  âš ï¸ æ‰¾ä¸åˆ° gaiji æ˜ å°„æ–‡ä»¶: {GAIJI_JSON}")
        _gaiji_map = {}
        return _gaiji_map
    with open(GAIJI_JSON, "r", encoding="utf-8") as f:
        _gaiji_map = json.load(f)
    return _gaiji_map

def resolve_gaiji(cb_id):
    """å°† CB ç¼–å·è§£æä¸ºå¯æ˜¾ç¤ºçš„å­—ç¬¦"""
    cb_id = cb_id.lstrip("#")
    gmap = _load_gaiji()
    entry = gmap.get(cb_id)
    if entry is None:
        return f"[{cb_id}]"
    # ä¼˜å…ˆçº§ï¼šç²¾ç¡® Unicode â†’ æ ‡å‡†åŒ– Unicode â†’ Big5 æ›¿ä»£ â†’ ç»„å­—å¼ â†’ CB ç¼–å·
    for key in ("uni_char", "norm_uni_char", "norm_big5_char", "composition"):
        if entry.get(key):
            return entry[key]
    return f"[{cb_id}]"

# ============================================================
# è—ç»åç§°æ˜ å°„
# ============================================================
_canons_cache = None

def _load_canons():
    """ä» canons.json è§£æè—ç»ä»£ç  â†’ ä¸­æ–‡åæ˜ å°„"""
    global _canons_cache
    if _canons_cache is not None:
        return _canons_cache
    _canons_cache = {}
    if not CANONS_JSON.exists():
        return _canons_cache
    try:
        with open(CANONS_JSON, "r", encoding="utf-8") as f:
            _canons_cache = json.load(f)
    except Exception as e:
        print(f"  âš ï¸ è¯»å– canons.json å¤±è´¥: {e}")
    return _canons_cache

# ============================================================
# å·¥å…·å‡½æ•°
# ============================================================
def _local_tag(element):
    """è·å–å…ƒç´ çš„æœ¬åœ°åï¼ˆå»é™¤å‘½åç©ºé—´ï¼‰"""
    tag = element.tag
    if "}" in tag:
        return tag.split("}")[1]
    return tag

def _clean_text(text):
    """æ¸…ç† XML æ ¼å¼åŒ–äº§ç”Ÿçš„å¤šä½™ç©ºç™½
    
    CBETA XML ä¸­ <lb> æ ‡ç­¾åçš„ç‰©ç†æ¢è¡Œåªæ˜¯ XML æ ¼å¼åŒ–ï¼Œ
    ä¸æ˜¯æœ‰æ„ä¹‰çš„æ®µè½æ–­è¡Œã€‚å°†æ¢è¡Œç¬¦æ›¿æ¢ä¸ºç©ºå­—ç¬¦ä¸²ï¼Œä¿ç•™å…¨è§’ç©ºæ ¼ã€‚
    """
    if not text:
        return text
    # å°†æ¢è¡Œç¬¦å’Œé¦–å°¾ç©ºç™½æ¸…é™¤ï¼ˆXML ä¸­çš„æ¢è¡Œåªæ˜¯æ ¼å¼åŒ–ï¼‰
    return text.replace('\n', '').replace('\r', '')

# è·³è¿‡æ ‡ç­¾é›†
SKIP_TAGS = {
    "rdg", "anchor", "back",
    "charDecl", "teiHeader",
    "docNumber",  # CBETA ç¼–ç›®å·ï¼ˆå¦‚ No. 251ï¼‰
}

SELF_CLOSING = {
    "lb", "pb", "milestone", "anchor", "space", "caesura",
}

# ä¸­æ–‡æ•°å­—æ˜ å°„
CN_NUMS = "ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å"

def juan_to_cn(n):
    """å°†é˜¿æ‹‰ä¼¯æ•°å­—å·å·è½¬ä¸ºä¸­æ–‡ï¼š1â†’ä¸€, 12â†’åäºŒ, 20â†’äºŒå"""
    if n <= 0:
        return str(n)
    if n <= 10:
        return CN_NUMS[n - 1]
    if n < 20:
        return f"å{CN_NUMS[n - 11]}"
    if n == 20:
        return "äºŒå"
    if n < 100:
        tens = n // 10
        ones = n % 10
        result = f"{CN_NUMS[tens - 1]}å"
        if ones > 0:
            result += CN_NUMS[ones - 1]
        return result
    return str(n)

# ============================================================
# çº¯æ–‡æœ¬æå–ï¼ˆç”¨äºå…ƒæ•°æ®å’Œè„šæ³¨ç­‰åœºæ™¯ï¼‰
# ============================================================
def get_text_recursive(element):
    """é€’å½’æå–çº¯æ–‡æœ¬"""
    parts = []
    if element.text:
        parts.append(element.text)
    for child in element:
        tag = _local_tag(child)
        if tag == "g":
            ref = child.get("ref", "")
            parts.append(resolve_gaiji(ref))
        elif tag == "lem":
            parts.append(get_text_recursive(child))
        elif tag == "app":
            parts.append(get_text_recursive(child))
        elif tag in SKIP_TAGS:
            pass
        elif tag == "space":
            quantity = child.get("quantity", "1")
            try:
                n = int(quantity)
            except ValueError:
                n = 1
            parts.append("ã€€" * n)
        elif tag == "caesura":
            parts.append("ã€€")
        elif tag == "choice":
            parts.append(get_text_recursive(child))
        elif tag in ("sic", "orig"):
            pass
        elif tag in ("corr", "reg"):
            parts.append(get_text_recursive(child))
        elif tag in SELF_CLOSING:
            pass
        else:
            parts.append(get_text_recursive(child))
        if child.tail:
            parts.append(child.tail)
    return "".join(parts)

# ============================================================
# Markdown æå–ï¼ˆæ ¸å¿ƒï¼šå°† XML é€’å½’è½¬ä¸º Markdownï¼‰
# ============================================================
def _parse_ref_target(target):
    """è§£æ <ref target="..."> ä¸º Obsidian wikilink æ ¼å¼
    
    ç¤ºä¾‹è¾“å…¥ï¼š../T30/T30n1579.xml#xpath2(//0279a03)
    è¾“å‡ºï¼šT30n1579ï¼ˆç»å·éƒ¨åˆ†ï¼‰
    """
    if not target:
        return ""
    # æå–æ–‡ä»¶åä¸­çš„ç»å·ï¼šT30n1579.xml â†’ T30n1579
    match = re.search(r'([A-Z]+\d+n[a-z]?\d+[a-z]?)', target)
    if match:
        return match.group(1)
    return ""


class MarkdownBuilder:
    """å¸¦çŠ¶æ€çš„ Markdown æ„å»ºå™¨ï¼Œè·Ÿè¸ªè„šæ³¨å’Œä¸Šä¸‹æ–‡"""

    def __init__(self):
        self.footnotes = []         # è„šæ³¨åˆ—è¡¨ [(id, content)]
        self.footnote_counter = 0
        self.in_verse = False       # æ˜¯å¦åœ¨åˆé¢‚ä¸­
        self.current_lb = ""        # å½“å‰è¡Œå·ï¼ˆç”¨äº Block IDï¼‰
        self.pending_block_id = ""  # å¾…è¾“å‡ºçš„ Block ID
        self.current_pb = ""        # å½“å‰é¡µç 

    def add_footnote(self, content):
        """æ·»åŠ è„šæ³¨ï¼Œè¿”å›è„šæ³¨æ ‡è®°"""
        self.footnote_counter += 1
        fn_id = self.footnote_counter
        self.footnotes.append((fn_id, content))
        return f"[^{fn_id}]"

    def get_md_recursive(self, element, depth=0):
        """é€’å½’å°† XML å…ƒç´ è½¬æ¢ä¸º Markdown"""
        parts = []
        if element.text:
            parts.append(_clean_text(element.text))

        for child in element:
            tag = _local_tag(child)

            # ---- Gaiji ç¼ºå­— ----
            if tag == "g":
                ref = child.get("ref", "")
                parts.append(resolve_gaiji(ref))

            # ---- è¡Œå· â†’ Block IDï¼ˆç”¨äº Obsidian æ®µè½å¼•ç”¨ï¼‰----
            elif tag == "lb":
                line_id = child.get("n", "")
                if line_id:
                    self.current_lb = line_id
                    self.pending_block_id = line_id

            # ---- é¡µç ï¼ˆè·³è¿‡ï¼Œä¸è¾“å‡ºé¡µç æ ‡è®°ï¼‰----
            elif tag == "pb":
                pass

            elif tag == "milestone":
                pass

            elif tag == "anchor":
                pass

            # ---- ç©ºæ ¼/åœé¡¿ ----
            elif tag == "space":
                quantity = child.get("quantity", "1")
                try:
                    n = int(quantity)
                except ValueError:
                    n = 1
                parts.append("ã€€" * n)

            elif tag == "caesura":
                parts.append("ã€€")

            # ---- æ ¡å‹˜ ----
            elif tag == "app":
                # åªå– <lem> æ­£æ–‡ï¼Œæ ¡å‹˜å¼‚è¯»ä¸è¾“å‡º
                for app_child in child:
                    ct = _local_tag(app_child)
                    if ct == "lem":
                        parts.append(self.get_md_recursive(app_child, depth + 1))
                        break

            elif tag == "lem":
                parts.append(self.get_md_recursive(child, depth + 1))

            elif tag == "rdg":
                # å•ç‹¬é‡åˆ° rdg è·³è¿‡ï¼ˆå·²åœ¨ app ä¸­å¤„ç†ï¼‰
                pass

            # ---- æ³¨é‡Š ----
            elif tag == "note":
                place = child.get("place", "")
                content = get_text_recursive(child).strip()
                if place == "inline" and content:
                    # å¤¹æ³¨ï¼šæ‹¬å·æ˜¾ç¤º
                    parts.append(f"ï¼ˆ{content}ï¼‰")
                # å…¶ä»–æ³¨é‡Šç±»å‹ï¼ˆæ ¡å‹˜ç­‰ï¼‰ä¸è¾“å‡º

            # ---- æ ‡é¢˜ ----
            elif tag == "head":
                head_text = self.get_md_recursive(child, depth + 1).strip()
                if head_text:
                    # mulu å·²ç”Ÿæˆç« èŠ‚æ ‡é¢˜æ—¶ï¼Œhead å¯èƒ½é‡å¤
                    # æ£€æŸ¥åŒä¸€ div ä¸‹æ˜¯å¦å·²æœ‰ mulu äº§ç”Ÿäº†æ ‡é¢˜
                    parent = element
                    has_mulu = any(
                        _local_tag(sib) == "mulu"
                        for sib in parent
                        if sib is not child
                    )
                    if not has_mulu:
                        parts.append(f"\n\n### {head_text}\n\n")
                    # å¦‚æœæœ‰ muluï¼Œhead æ–‡å­—ä¸é‡å¤è¾“å‡º

            # ---- ä½œè€… ----
            elif tag == "byline":
                byline_text = self.get_md_recursive(child, depth + 1).strip()
                if byline_text:
                    parts.append(f"\n\n*{byline_text}*\n\n")

            elif tag == "trailer":
                trailer_text = self.get_md_recursive(child, depth + 1).strip()
                if trailer_text:
                    parts.append(f"\n\n---\n*{trailer_text}*\n\n")

            # ---- æ®µè½ ----
            elif tag == "p":
                cb_type = child.get(f"{{{CB_NS}}}type", "")
                p_text = self.get_md_recursive(child, depth + 1).strip()
                if p_text:
                    # é™„åŠ  Block IDï¼ˆæ®µè½çº§ï¼Œå–æ®µè½å†…æœ€åä¸€ä¸ªè¡Œå·ï¼‰
                    block_id_str = ""
                    if self.pending_block_id:
                        block_id_str = f" ^{self.pending_block_id}"
                        self.pending_block_id = ""
                    if cb_type == "dharani":
                        parts.append(f"\n\n> ğŸ”” {p_text}\n\n")
                    else:
                        parts.append(f"\n\n{p_text}{block_id_str}\n\n")

            # ---- åˆé¢‚ ----
            elif tag == "lg":
                self.in_verse = True
                verse_content = self.get_md_recursive(child, depth + 1)
                self.in_verse = False
                parts.append(f"\n\n{verse_content}\n\n")

            elif tag == "l":
                line_text = self.get_md_recursive(child, depth + 1).strip()
                if line_text:
                    parts.append(f"> {line_text}  \n")

            # ---- å·æ ‡è®° ----
            elif tag == "juan":
                fun = child.get("fun", "")
                if fun == "close":
                    # å·å°¾æ ‡è®°
                    juan_text = get_text_recursive(child).strip()
                    if juan_text:
                        parts.append(f"\n\n---\n*{juan_text}*\n\n")
                # fun="open" è·³è¿‡ï¼šå·æ ‡é¢˜å·²ç”± convert_sutra_group ç”Ÿæˆ

            elif tag == "jhead":
                pass  # å·²ç”± <juan> ç”Ÿæˆå·æ ‡é¢˜ï¼Œjhead è·³è¿‡é¿å…æ··ä¹±

            # ---- ä¸­å¤–å¯¹ç…§æœ¯è¯­ï¼ˆcb:tt / cb:tï¼‰â†’ åªå–ä¸­æ–‡ ----
            elif tag == "tt":
                for tt_child in child:
                    if _local_tag(tt_child) == "t":
                        lang = tt_child.get(f"{{{XML_NS}}}lang", "")
                        if "zh" in lang:
                            parts.append(self.get_md_recursive(tt_child, depth + 1))
                            break

            elif tag == "t":
                parts.append(self.get_md_recursive(child, depth + 1))

            # ---- ç›®å½•æ ‡è®° â†’ Markdown æ ‡é¢˜ ----
            elif tag == "mulu":
                mulu_type = child.get("type", "")
                level = child.get("level", "1")
                title = get_text_recursive(child).strip() or child.get("n", "")
                if title and mulu_type != "å·":
                    # å·æ ‡è®°å·²ç”± <juan> å¤„ç†ï¼Œé¿å…é‡å¤
                    # level 1 â†’ ###, level 2 â†’ ####, level 3 â†’ #####
                    try:
                        md_level = min(int(level) + 2, 6)  # h3 ~ h6
                    except ValueError:
                        md_level = 3
                    heading = "#" * md_level
                    parts.append(f"\n\n{heading} {title}\n\n")

            # ---- div ç« èŠ‚ ----
            elif tag == "div":
                div_content = self.get_md_recursive(child, depth + 1)
                parts.append(div_content)

            # ---- åˆ—è¡¨ ----
            elif tag == "list":
                list_content = self.get_md_recursive(child, depth + 1)
                parts.append(f"\n\n{list_content}\n\n")

            elif tag == "item":
                item_text = self.get_md_recursive(child, depth + 1).strip()
                n = child.get("n", "")
                prefix = f"{n}. " if n else "- "
                parts.append(f"{prefix}{item_text}\n")

            # ---- è¡¨æ ¼ ----
            elif tag == "table":
                rows = []
                for row_elem in child:
                    if _local_tag(row_elem) == "row":
                        cells = []
                        for cell_elem in row_elem:
                            if _local_tag(cell_elem) == "cell":
                                cells.append(get_text_recursive(cell_elem).strip())
                        rows.append(cells)
                if rows:
                    # è¾“å‡º Markdown è¡¨æ ¼
                    max_cols = max(len(r) for r in rows)
                    parts.append("\n\n")
                    for i, row in enumerate(rows):
                        # è¡¥é½åˆ—æ•°
                        while len(row) < max_cols:
                            row.append("")
                        parts.append("| " + " | ".join(row) + " |\n")
                        if i == 0:
                            parts.append("| " + " | ".join(["---"] * max_cols) + " |\n")
                    parts.append("\n")

            # ---- å¼•æ–‡ ----
            elif tag == "quote":
                quote_text = self.get_md_recursive(child, depth + 1).strip()
                if quote_text:
                    parts.append(f"\n\n> {quote_text}\n\n")

            # ---- æ¨¡ç³Šå­— ----
            elif tag == "unclear":
                unclear_text = self.get_md_recursive(child, depth + 1)
                parts.append(f"ã€”{unclear_text}ã€•")

            # ---- å¤–è¯­ ----
            elif tag == "foreign":
                parts.append(f"*{self.get_md_recursive(child, depth + 1)}*")

            # ---- æ ¼å¼åŒ– ----
            elif tag == "hi":
                rend = child.get("rend", "")
                inner = self.get_md_recursive(child, depth + 1)
                if "bold" in rend:
                    parts.append(f"**{inner}**")
                else:
                    parts.append(inner)

            # ---- äº¤å‰å¼•ç”¨ â†’ Obsidian wikilink ----
            elif tag == "ref":
                target = child.get("target", "")
                ref_text = self.get_md_recursive(child, depth + 1).strip()
                sutra_ref = _parse_ref_target(target)
                if ref_text and sutra_ref:
                    # è½¬ä¸º Obsidian wikilinkï¼š[[T30n1579|è«–æœ¬å·ç¬¬ä¸€]]
                    parts.append(f"[[{sutra_ref}|{ref_text}]]")
                elif ref_text:
                    parts.append(ref_text)

            # ---- æ­£åˆ™åŒ–/æ ¡æ­£ ----
            elif tag == "choice":
                parts.append(self.get_md_recursive(child, depth + 1))

            elif tag in ("corr", "reg"):
                parts.append(self.get_md_recursive(child, depth + 1))

            elif tag in ("sic", "orig"):
                pass

            # ---- header/skip ----
            elif tag in SKIP_TAGS:
                pass

            # ---- æ‰€æœ‰å…¶ä½™å…ƒç´ ï¼šé€’å½’æå– ----
            else:
                parts.append(self.get_md_recursive(child, depth + 1))

            if child.tail:
                parts.append(_clean_text(child.tail))

        return "".join(parts)

    def build_footnotes_section(self):
        """ç”Ÿæˆè„šæ³¨åŒºåŸŸ"""
        if not self.footnotes:
            return ""
        lines = ["\n\n---\n"]
        for fn_id, content in self.footnotes:
            lines.append(f"[^{fn_id}]: {content}\n")
        return "\n".join(lines)


# ============================================================
# å…ƒæ•°æ®æå–
# ============================================================
def extract_metadata(tree):
    """ä» teiHeader æå–ç»æ–‡å…ƒæ•°æ®"""
    root = tree.getroot()

    xml_id = root.get(f"{{{XML_NS}}}id", "")

    # è§£æç»å·ï¼ˆæ”¯æŒ T08n0251, J01nA042, X10na096 ç­‰æ ¼å¼ï¼‰
    match = re.match(r"([A-Z]+)(\d+)n([A-Za-z]*)(\d+[a-z]?)", xml_id)
    if match:
        canon = match.group(1)
        volume = match.group(2)
        sutra_no_prefix = match.group(3)
        sutra_no_digits = match.group(4)
        sutra_no = sutra_no_prefix + sutra_no_digits
        sutra_id = f"{canon}{sutra_no.zfill(4)}"
    else:
        canon = ""
        volume = ""
        sutra_id = xml_id

    # ç»å
    title = xml_id
    for title_elem in root.iter(f"{{{TEI_NS}}}title"):
        if (
            title_elem.get("level") == "m"
            and title_elem.get(f"{{{XML_NS}}}lang") == "zh-Hant"
        ):
            extracted = get_text_recursive(title_elem).strip()
            if extracted:
                title = extracted
            break

    # ä½œè€…
    author = ""
    author_elem = root.find(f".//{{{TEI_NS}}}titleStmt/{{{TEI_NS}}}author")
    if author_elem is not None and author_elem.text:
        author = author_elem.text.strip()

    # å·æ•°
    total_juan = 1
    extent_elem = root.find(f".//{{{TEI_NS}}}extent")
    if extent_elem is not None and extent_elem.text:
        juan_match = re.search(r"(\d+)", extent_elem.text)
        if juan_match:
            total_juan = int(juan_match.group(1))

    # è—ç»å
    canons = _load_canons()
    category = canons.get(canon, {}).get("title-zh", "")

    return {
        "sutra_id": sutra_id,
        "canon": canon,
        "volume": volume,
        "title": title,
        "author": author,
        "total_juan": total_juan,
        "category": category,
        "xml_id": xml_id,
    }


# ============================================================
# ä» Bookcase åˆ†å· XML åˆå¹¶ä¸ºä¸€ä¸ª Markdown
# ============================================================
def convert_sutra_group(xml_files, output_base, verbose=True):
    """å°†åŒä¸€éƒ¨ç»çš„å¤šä¸ªåˆ†å· XML åˆå¹¶ä¸ºä¸€ä¸ª MD æ–‡ä»¶
    
    xml_files: æŒ‰å·æ’åºçš„ XML æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    è¿”å›: å…ƒæ•°æ® dict æˆ– None
    """
    if not xml_files:
        return None

    # 1. ä»ç¬¬ä¸€ä¸ªæ–‡ä»¶æå–å…ƒæ•°æ®
    first_file = xml_files[0]
    try:
        tree = ET.parse(str(first_file))
    except ET.ParseError as e:
        print(f"  âŒ XML è§£æå¤±è´¥: {first_file} - {e}")
        return None

    meta = extract_metadata(tree)
    if verbose:
        print(f"  ğŸ“– {meta['xml_id']} {meta['title']} ({len(xml_files)} å·)")

    # 2. é€å·è§£æå¹¶åˆå¹¶ Markdown
    builder = MarkdownBuilder()
    all_parts = []
    back_notes_parts = []

    for idx, xml_path in enumerate(xml_files):
        juan_num = _parse_juan_from_filename(xml_path)

        try:
            t = ET.parse(str(xml_path))
        except ET.ParseError:
            continue

        root = t.getroot()
        body = root.find(f".//{{{TEI_NS}}}body")
        if body is None:
            continue

        # å·æ ‡é¢˜åˆ†éš”ï¼ˆå¤šå·ç»æ‰è¾“å‡ºï¼‰
        if len(xml_files) > 1:
            juan_cn = juan_to_cn(juan_num)
            all_parts.append(f"\n\n## å·{juan_cn}\n\n")

        # è½¬æ¢æ­£æ–‡
        md_text = builder.get_md_recursive(body)
        all_parts.append(md_text)

        # <back> æ ¡å‹˜æ³¨ä¸æå–ï¼ˆé˜…è¯»å™¨å·²ä¿ç•™ï¼‰

    if not all_parts:
        return None

    # 3. ç»„è£…å®Œæ•´ Markdown
    frontmatter = f"""---
sutra_id: {meta['sutra_id']}
title: {meta['title']}
author: {meta['author']}
canon: {meta['category']}
volume: "{meta['volume']}"
total_juan: {meta['total_juan']}
cbeta_id: {meta['xml_id']}
tags:
  - ä½›ç¶“
  - {meta['canon']}è—
---

"""
    header = f"# {meta['title']}\n\n"
    content = "".join(all_parts).strip()
    content = re.sub(r'\n{3,}', '\n\n', content)

    full_md = frontmatter + header + content




    # 4. å†™å…¥æ–‡ä»¶
    safe_title = re.sub(r'[\\/:*?"<>|]', '_', meta['title'])
    sutra_dir = Path(output_base) / "ç¶“æ–‡" / meta['canon'] / f"{meta['canon']}{meta['volume']}"
    sutra_dir.mkdir(parents=True, exist_ok=True)

    filename = f"{meta['xml_id']}_{safe_title}.md"
    filepath = sutra_dir / filename
    with open(filepath, "w", encoding="utf-8") as f:
        f.write(full_md)

    if verbose:
        print(f"     âœ… â†’ {filepath.relative_to(output_base)}")

    # ä¿å­˜æ–‡ä»¶åä¿¡æ¯ï¼Œä¾›ç›®å½•ç”Ÿæˆæ—¶ä½¿ç”¨
    meta['_link_name'] = f"{meta['xml_id']}_{safe_title}"

    return meta


def _parse_juan_from_filename(xml_path):
    """ä» Bookcase æ–‡ä»¶åè§£æå·å·ï¼šT01n0001_003.xml â†’ 3"""
    m = re.search(r"_(\d+)\.xml$", str(xml_path))
    if m:
        return int(m.group(1))
    return 1


# ============================================================
# éƒ¨ç±»åˆ†ç±»ï¼ˆä» bulei_nav.xhtml è§£æï¼‰
# ============================================================
_bulei_map = None

def _load_bulei_map():
    """è§£æ bulei_nav.xhtmlï¼Œå»ºç«‹ ç»å·â†’éƒ¨ç±» æ˜ å°„"""
    global _bulei_map
    if _bulei_map is not None:
        return _bulei_map

    _bulei_map = {}
    if not BULEI_NAV.exists():
        print(f"  âš ï¸ æ‰¾ä¸åˆ° bulei_nav: {BULEI_NAV}ï¼Œä½¿ç”¨é»˜è®¤åˆ†ç±»")
        return _bulei_map

    with open(BULEI_NAV, "r", encoding="utf-8") as f:
        content = f.read()

    # æå–éƒ¨ç±»åç§°ï¼ˆ<span> æ ‡ç­¾ä¸­çš„é¡¶å±‚åˆ†ç±»ï¼‰
    # æ ¼å¼: <span>01 é˜¿å«éƒ¨é¡ T01-02,25,33 etc.</span>
    current_category = "å…¶ä»–"
    for line in content.split('\n'):
        # åŒ¹é…éƒ¨ç±»æ ‡é¢˜
        cat_match = re.search(r'<span>\d+\s+(.+?)\s+[A-Z]', line)
        if cat_match:
            current_category = cat_match.group(1).strip()

        # åŒ¹é…ç»æ–‡æ¡ç›®
        # <cblink href="XML/T/T01/T01n0001_001.xml">T0001 é•·é˜¿å«ç¶“</cblink>
        entry_match = re.search(r'>([A-Z]+\d+[a-z]?)\s', line)
        if entry_match and '<cblink' in line:
            sutra_id = entry_match.group(1)
            _bulei_map[sutra_id] = current_category

    return _bulei_map


def get_category(meta):
    """è·å–ç»æ–‡çš„éƒ¨ç±»åˆ†ç±»"""
    bulei = _load_bulei_map()
    # å°è¯•åŒ¹é… sutra_id
    cat = bulei.get(meta.get('sutra_id', ''))
    if cat:
        return cat
    # å›é€€ï¼šç”¨è—ç»å
    canons = _load_canons()
    name = canons.get(meta.get('canon', ''), {}).get("short-title-zh", "")
    return name if name else (meta.get('canon', '') or "å…¶ä»–")


# ============================================================
# ç”Ÿæˆ Vault ç»“æ„ï¼ˆç›®å½•ã€é¦–é¡µã€ç¬”è®°æ–‡ä»¶å¤¹ï¼‰
# ============================================================
def generate_vault_structure(output_base, all_meta):
    """åœ¨è½¬æ¢å®Œæˆåç”Ÿæˆ Vault çš„ç´¢å¼•ç»“æ„"""
    output_base = Path(output_base)
    canons_data = _load_canons()

    print("\nğŸ“‚ ç”Ÿæˆ Vault ç»“æ„...")

    # --- ç›®å½•/ç¶“è—/ ---
    canon_dir = output_base / "ç›®éŒ„" / "ç¶“è—"
    canon_dir.mkdir(parents=True, exist_ok=True)

    by_canon = {}
    for m in all_meta:
        code = m['canon']
        if code not in by_canon:
            by_canon[code] = []
        by_canon[code].append(m)

    for code in sorted(by_canon.keys()):
        sutras = by_canon[code]
        canon_name = canons_data.get(code, {}).get("short-title-zh", "") or code
        canon_full = canons_data.get(code, {}).get("title-zh", code)

        lines = [f"---\ntype: moc\ntags: [ç¶“è—ç›®éŒ„]\n---\n\n"]
        lines.append(f"# {canon_full}\n\n")
        lines.append(f"ç¶“æ•¸ï¼š{len(sutras)} éƒ¨\n\n")

        by_vol = {}
        for m in sutras:
            v = m.get('volume', '??')
            if v not in by_vol:
                by_vol[v] = []
            by_vol[v].append(m)

        for vol in sorted(by_vol.keys()):
            lines.append(f"### ç¬¬ {vol} å†Š\n\n")
            for m in by_vol[vol]:
                author = f" â€” {m['author']}" if m['author'] else ""
                link = m.get('_link_name', m['title'])
                lines.append(f"- [[{link}|{m['sutra_id']} {m['title']}]]{author}\n")
            lines.append("\n")

        filepath = canon_dir / f"{canon_name}.md"
        with open(filepath, "w", encoding="utf-8") as f:
            f.write("".join(lines))
        print(f"  ğŸ“š ç¶“è—: {canon_name} ({len(sutras)} éƒ¨)")

    # --- ç›®å½•/éƒ¨é¡/ ---
    cat_dir = output_base / "ç›®éŒ„" / "éƒ¨é¡"
    cat_dir.mkdir(parents=True, exist_ok=True)

    by_cat = {}
    for m in all_meta:
        cat = get_category(m)
        if cat not in by_cat:
            by_cat[cat] = []
        by_cat[cat].append(m)

    for cat_name in sorted(by_cat.keys()):
        sutras = by_cat[cat_name]
        lines = [f"---\ntype: moc\ntags: [éƒ¨é¡ç›®éŒ„]\n---\n\n"]
        lines.append(f"# {cat_name}\n\n")
        lines.append(f"ç¶“æ•¸ï¼š{len(sutras)} éƒ¨\n\n")

        for m in sutras:
            author = f" â€” {m['author']}" if m['author'] else ""
            link = m.get('_link_name', m['title'])
            lines.append(f"- [[{link}|{m['sutra_id']} {m['title']}]]{author}\n")

        filepath = cat_dir / f"{cat_name}.md"
        with open(filepath, "w", encoding="utf-8") as f:
            f.write("".join(lines))
        print(f"  ğŸ“– éƒ¨é¡: {cat_name} ({len(sutras)} éƒ¨)")

    # --- é¦–é .md ---
    homepage = ["---\ntype: homepage\n---\n\n"]
    homepage.append("# ğŸ“› æ³•å°å°ç…§ CBETA ä½›ç¶“ Vault\n\n")
    homepage.append(f"å…±è¨ˆ {len(all_meta)} éƒ¨ç¶“å…¸\n\n")

    homepage.append("## éƒ¨é¡ç´¢å¼•\n\n")
    for cat_name in sorted(by_cat.keys()):
        count = len(by_cat[cat_name])
        homepage.append(f"- [[{cat_name}]]  ({count} éƒ¨)\n")

    homepage.append("\n## ç¶“è—ç´¢å¼•\n\n")
    for code in sorted(by_canon.keys()):
        canon_name = canons_data.get(code, {}).get("short-title-zh", "") or code
        count = len(by_canon[code])
        homepage.append(f"- [[{canon_name}]]  ({count} éƒ¨)\n")

    homepage.append("\n## ğŸ“ ç­†è¨˜\n\n")
    homepage.append("åœ¨ `ç­†è¨˜/` æ–‡ä»¶å¤¾ä¸­å‰µå»ºè®€ç¶“ç­†è¨˜ï¼Œä½¿ç”¨ Block ID ç²¾ç¢ºå¼•ç”¨ç¶“æ–‡ã€‚\n")

    with open(output_base / "é¦–é .md", "w", encoding="utf-8") as f:
        f.write("".join(homepage))
    print("  ğŸ  é¦–é .md")

    # --- ç­†è¨˜/ ---
    notes_dir = output_base / "ç­†è¨˜"
    notes_dir.mkdir(parents=True, exist_ok=True)
    readme = "---\ntype: folder-note\n---\n\n# ğŸ“ è®€ç¶“ç­†è¨˜\n\nåœ¨æ­¤æ–‡ä»¶å¤¾ä¸­å‰µå»ºç­†è¨˜ã€‚\n\n## å»ºè­°\n\n- ä½¿ç”¨ `![[ç¶“å#^0848c07]]` åµŒå…¥ç¶“æ–‡\n- ä½¿ç”¨ `> [!note] çœ‰æ‰¹` åšæ®µè½æ‰¹æ³¨\n- æ¨™ç±¤ï¼š`#è®€ç¶“` `#å¿ƒå¾—` `#ç–‘å•†`\n"
    with open(notes_dir / "è®€ç¶“ç­†è¨˜.md", "w", encoding="utf-8") as f:
        f.write(readme)
    print("  ğŸ“ ç­†è¨˜/è®€ç¶“ç­†è¨˜.md")


# ============================================================
# æ–‡ä»¶å‘ç°ä¸åˆ†ç»„
# ============================================================
def find_sutra_groups(canon=None):
    """æ‰«æ Bookcase XML æ–‡ä»¶ï¼ŒæŒ‰ç»å·åˆ†ç»„
    
    è¿”å›: [(sutra_key, [xml_file_paths_sorted_by_juan])]
    sutra_key = å¦‚ "T01n0001"ï¼ˆç”¨äºæ’åºå’Œå»é‡ï¼‰
    """
    if canon:
        pattern = str(XML_BASE / canon / "**" / "*.xml")
    else:
        pattern = str(XML_BASE / "**" / "*.xml")

    all_files = sorted(glob.glob(pattern, recursive=True))

    # æŒ‰ç»å·å‰ç¼€åˆ†ç»„ï¼šT01n0001_001.xml â†’ T01n0001
    groups = {}
    for f in all_files:
        basename = Path(f).stem  # T01n0001_001
        # å»æ‰ _NNN åç¼€
        sutra_key = re.sub(r'_\d+$', '', basename)
        if sutra_key not in groups:
            groups[sutra_key] = []
        groups[sutra_key].append(f)

    # æ¯ç»„å†…æŒ‰æ–‡ä»¶åæ’åºï¼ˆç¡®ä¿å·æ¬¡é¡ºåºï¼‰
    result = []
    for key in sorted(groups.keys()):
        result.append((key, sorted(groups[key])))

    return result


# ============================================================
# ä¸»ç¨‹åº
# ============================================================
def main():
    parser = argparse.ArgumentParser(
        description="CBETA Bookcase XML â†’ Obsidian Markdown è½¬æ¢å™¨ï¼ˆä¸€ç»ä¸€æ–‡ä»¶ï¼‰"
    )
    parser.add_argument("--sutra", type=str, help="è½¬æ¢å•éƒ¨ç»ï¼Œå¦‚ T08n0251")
    parser.add_argument("--canon", type=str, help="è½¬æ¢æ•´ä¸ªè—ç»ï¼Œå¦‚ T, X, J")
    parser.add_argument("--all", action="store_true", help="è½¬æ¢å…¨éƒ¨")
    parser.add_argument("--limit", type=int, default=0, help="é™åˆ¶è½¬æ¢æ•°é‡")
    parser.add_argument("--output", type=str, default=str(OUTPUT_DIR), help="è¾“å‡ºç›®å½•")
    args = parser.parse_args()

    output_dir = Path(args.output)
    output_dir.mkdir(parents=True, exist_ok=True)

    print("=" * 60)
    print("CBETA Bookcase XML â†’ Obsidian Markdownï¼ˆä¸€ç»ä¸€æ–‡ä»¶ï¼‰")
    print("=" * 60)
    print(f"XML æ¥æº: {XML_BASE}")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")
    print()

    start_time = time.time()
    success_count = 0
    fail_count = 0
    all_meta = []

    if args.sutra:
        # å•ç»æ¨¡å¼ï¼šT08n0251 â†’ æ‰¾ T/T08/T08n0251_*.xml
        match = re.match(r"([A-Z]+)(\d+)n", args.sutra)
        if match:
            canon = match.group(1)
            vol = match.group(1) + match.group(2)
            pattern = str(XML_BASE / canon / vol / f"{args.sutra}_*.xml")
            xml_files = sorted(glob.glob(pattern))
        else:
            print(f"âŒ æ— æ³•è§£æç»å·: {args.sutra}")
            sys.exit(1)

        if not xml_files:
            print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {args.sutra}")
            sys.exit(1)

        result = convert_sutra_group(xml_files, output_dir)
        if result:
            all_meta.append(result)
            success_count += 1
        else:
            fail_count += 1

    elif args.canon or args.all:
        canon = args.canon if args.canon else None
        groups = find_sutra_groups(canon)
        total = len(groups)
        if args.limit > 0:
            groups = groups[:args.limit]
        print(f"æ‰¾åˆ° {total} éƒ¨ç»ï¼Œå°†è½¬æ¢ {len(groups)} éƒ¨\n")

        for i, (sutra_key, xml_files) in enumerate(groups, 1):
            print(f"[{i}/{len(groups)}]")
            result = convert_sutra_group(xml_files, output_dir)
            if result:
                all_meta.append(result)
                success_count += 1
            else:
                fail_count += 1

    else:
        parser.print_help()
        sys.exit(0)

    # ç”Ÿæˆ Vault ç»“æ„
    if all_meta:
        generate_vault_structure(output_dir, all_meta)

    elapsed = time.time() - start_time
    print()
    print("=" * 60)
    print(f"è½¬æ¢å®Œæˆï¼")
    print(f"  âœ… æˆåŠŸ: {success_count}")
    print(f"  âŒ å¤±è´¥: {fail_count}")
    print(f"  â±ï¸  è€—æ—¶: {elapsed:.1f} ç§’")
    print(f"  ğŸ“‚ è¾“å‡º: {output_dir}")
    print("=" * 60)


if __name__ == "__main__":
    main()

