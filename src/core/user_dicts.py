"""
ç”¨æˆ·è¯å…¸é€‚é…å™¨

æ”¯æŒç”¨æˆ·è‡ªè¡Œæ”¾ç½®çš„è¯å…¸æ–‡ä»¶ï¼Œè‡ªåŠ¨æ‰«æ data/dicts/user/ ç›®å½•ã€‚
æ”¯æŒæ ¼å¼: MDX, JSON, CSV

ç”¨æ³•:
    from core.user_dicts import UserDictManager
    mgr = UserDictManager(Path("data/dicts/user"))
    results = mgr.lookup("èˆ¬è‹¥")
"""

import csv
import json
import logging
import re
import time
from pathlib import Path
from typing import Optional

log = logging.getLogger(__name__)

# â”€â”€ MDX è¯»å–å™¨ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class MdxDictionary:
    """MDict (.mdx) è¯å…¸è¯»å–å™¨"""

    def __init__(self, mdx_path: Path):
        from mdict_utils import reader as mdict_reader
        self.path = mdx_path
        self.name = mdx_path.stem  # æ–‡ä»¶åä½œä¸ºè¯å…¸å
        self.dict_id = f"user.mdx.{self.name}"
        self._index: dict[str, list[str]] = {}  # term â†’ [definition, ...]
        self._loaded = False
        self._entry_count = 0

    def _ensure_loaded(self):
        """å»¶è¿ŸåŠ è½½ï¼šé¦–æ¬¡æŸ¥è¯¢æ—¶æ‰æ„å»ºç´¢å¼•"""
        if self._loaded:
            return
        start = time.time()
        try:
            from mdict_utils import reader as mdict_reader
            md = mdict_reader.MDX(str(self.path))
            items = md.items()
            for key_bytes, val_bytes in items:
                try:
                    key = key_bytes.decode("utf-8") if isinstance(key_bytes, bytes) else str(key_bytes)
                    val = val_bytes.decode("utf-8") if isinstance(val_bytes, bytes) else str(val_bytes)
                except (UnicodeDecodeError, AttributeError):
                    continue

                key = key.strip()
                if not key:
                    continue

                if key not in self._index:
                    self._index[key] = []
                self._index[key].append(val)

            self._entry_count = len(self._index)
            elapsed = time.time() - start
            log.info(f"  MDX åŠ è½½å®Œæˆ: {self.name} ({self._entry_count} è¯æ¡, {elapsed:.1f}ç§’)")
        except Exception as e:
            log.error(f"  MDX åŠ è½½å¤±è´¥: {self.path}: {e}")
        self._loaded = True

    def lookup(self, term: str) -> list[dict]:
        """æŸ¥è¯¢è¯æ¡ï¼Œè¿”å›ç»“æœåˆ—è¡¨"""
        self._ensure_loaded()
        results = []
        definitions = self._index.get(term, [])
        for defn in definitions:
            results.append({
                "dict_id": self.dict_id,
                "dict_name": self.name,
                "char_type": "ç”¨æˆ·è¯å…¸",
                "term": term,
                "definition": defn,
            })
        return results

    @property
    def info(self) -> dict:
        """è¯å…¸ä¿¡æ¯"""
        self._ensure_loaded()
        return {
            "dict_id": self.dict_id,
            "name": self.name,
            "source": f"ç”¨æˆ·è¯å…¸ (MDX): {self.path.name}",
            "entry_count": self._entry_count,
            "char_type": "ç”¨æˆ·è¯å…¸",
        }


# â”€â”€ JSON è¯»å–å™¨ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class JsonDictionary:
    """
    JSON è¯å…¸è¯»å–å™¨

    æ”¯æŒå¤šç§æ ¼å¼:
    1. å¯¹è±¡æ ¼å¼: {"èˆ¬è‹¥": "æ™ºæ…§", "æ¶…æ§ƒ": "å¯‚ç­"}
    2. æ•°ç»„æ ¼å¼: [{"term": "èˆ¬è‹¥", "definition": "æ™ºæ…§"}, ...]
    3. èŒå…¸æ ¼å¼: [{"title": "èˆ¬è‹¥", "heteronyms": [{"bopomofo": "...", "definitions": [{"def": "..."}]}]}, ...]
    4. å…¶ä»–å¸¸è§æ ¼å¼: word/headword/key + meaning/def/explanation ç­‰å­—æ®µå
    """

    # å¸¸è§çš„"è¯æ¡"å­—æ®µå
    TERM_FIELDS = ("term", "è¯æ¡", "word", "headword", "key", "title", "entry")
    # å¸¸è§çš„"é‡Šä¹‰"å­—æ®µå
    DEFN_FIELDS = ("definition", "é‡Šä¹‰", "è§£é‡Š", "meaning", "def", "explanation", "value", "content")

    def __init__(self, json_path: Path):
        self.path = json_path
        self.name = json_path.stem
        self.dict_id = f"user.json.{self.name}"
        self._index: dict[str, list[str]] = {}
        self._loaded = False
        self._entry_count = 0

    @staticmethod
    def _find_field(item: dict, candidates: tuple) -> str:
        """åœ¨å­—å…¸ä¸­æŸ¥æ‰¾ç¬¬ä¸€ä¸ªåŒ¹é…çš„å­—æ®µåï¼Œè¿”å›å…¶å€¼"""
        for field in candidates:
            if field in item:
                return str(item[field]).strip()
        return ""

    @staticmethod
    def _flatten_moedict(item: dict) -> list[str]:
        """
        å±•å¹³èŒå…¸æ ¼å¼çš„åµŒå¥—ç»“æ„ï¼Œæå–æ‰€æœ‰è¯»éŸ³+é‡Šä¹‰ã€‚
        è¿”å›æ ¼å¼: ["ã€ã„…ã„› ã„–ã„œË‡ã€‘bÅ rÄ›\nâ¶ æ™ºæ…§...\nâ· ...", ...]
        """
        results = []
        heteronyms = item.get("heteronyms", [])
        if not isinstance(heteronyms, list):
            return results

        for het in heteronyms:
            if not isinstance(het, dict):
                continue
            parts = []
            # æå–è¯»éŸ³ï¼ˆæ³¨éŸ³ + æ‹¼éŸ³åŒæ—¶æ˜¾ç¤ºï¼‰
            bopomofo = het.get("bopomofo", "")
            pinyin = het.get("pinyin", "")
            reading_parts = []
            if bopomofo:
                reading_parts.append(bopomofo)
            if pinyin:
                reading_parts.append(pinyin)
            if reading_parts:
                parts.append("ã€" + " / ".join(reading_parts) + "ã€‘")

            # æå–é‡Šä¹‰
            definitions = het.get("definitions", [])
            if isinstance(definitions, list):
                circled = "â¶â·â¸â¹âºâ»â¼â½â¾â¿"
                for i, d in enumerate(definitions):
                    if isinstance(d, dict):
                        defn = d.get("def", "")
                        if defn:
                            prefix = circled[i] if i < len(circled) else f"({i+1})"
                            entry = f"{prefix} {defn}"
                            # é™„åŠ å¼•ç”¨å‡ºå¤„
                            quote = d.get("quote", [])
                            if isinstance(quote, list):
                                for q in quote:
                                    entry += f"\nã€€ã€€ğŸ“– {q}"
                            elif isinstance(quote, str) and quote:
                                entry += f"\nã€€ã€€ğŸ“– {quote}"
                            # é™„åŠ ä¾‹å¥
                            example = d.get("example", [])
                            if isinstance(example, list):
                                for ex in example:
                                    entry += f"\nã€€ã€€ä¾‹ï¼š{ex}"
                            elif isinstance(example, str) and example:
                                entry += f"\nã€€ã€€ä¾‹ï¼š{example}"
                            parts.append(entry)

            if parts:
                results.append("\n".join(parts))
        return results

    def _ensure_loaded(self):
        if self._loaded:
            return
        start = time.time()
        try:
            data = json.loads(self.path.read_text(encoding="utf-8"))

            if isinstance(data, dict):
                # å¯¹è±¡æ ¼å¼: {"term": "definition"}
                for k, v in data.items():
                    k = str(k).strip()
                    if k:
                        if isinstance(v, str):
                            self._index[k] = [v]
                        elif isinstance(v, list):
                            self._index[k] = [str(item) for item in v]
                        else:
                            self._index[k] = [str(v)]

            elif isinstance(data, list):
                for item in data:
                    if not isinstance(item, dict):
                        continue

                    # æå–è¯æ¡å
                    term = self._find_field(item, self.TERM_FIELDS)
                    if not term:
                        continue

                    # ç­–ç•¥1: èŒå…¸åµŒå¥—æ ¼å¼ (heteronyms)
                    if "heteronyms" in item:
                        defns = self._flatten_moedict(item)
                        if defns:
                            if term not in self._index:
                                self._index[term] = []
                            self._index[term].extend(defns)
                            continue

                    # ç­–ç•¥2: ç®€å•å­—æ®µæ ¼å¼
                    defn = self._find_field(item, self.DEFN_FIELDS)
                    if defn:
                        if term not in self._index:
                            self._index[term] = []
                        self._index[term].append(defn)

            self._entry_count = len(self._index)
            elapsed = time.time() - start
            log.info(f"  JSON åŠ è½½å®Œæˆ: {self.name} ({self._entry_count} è¯æ¡, {elapsed:.1f}ç§’)")
        except Exception as e:
            log.error(f"  JSON åŠ è½½å¤±è´¥: {self.path}: {e}")
        self._loaded = True

    def lookup(self, term: str) -> list[dict]:
        self._ensure_loaded()
        results = []
        definitions = self._index.get(term, [])
        for defn in definitions:
            results.append({
                "dict_id": self.dict_id,
                "dict_name": self.name,
                "char_type": "ç”¨æˆ·è¯å…¸",
                "term": term,
                "definition": defn,
            })
        return results

    @property
    def info(self) -> dict:
        self._ensure_loaded()
        return {
            "dict_id": self.dict_id,
            "name": self.name,
            "source": f"ç”¨æˆ·è¯å…¸ (JSON): {self.path.name}",
            "entry_count": self._entry_count,
            "char_type": "ç”¨æˆ·è¯å…¸",
        }


# â”€â”€ CSV è¯»å–å™¨ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class CsvDictionary:
    """
    CSV è¯å…¸è¯»å–å™¨

    è¦æ±‚ç¬¬ä¸€è¡Œä¸ºè¡¨å¤´ï¼Œå¿…é¡»åŒ…å« term/è¯æ¡ å’Œ definition/é‡Šä¹‰ åˆ—ã€‚
    ç¤ºä¾‹:
        term,definition
        èˆ¬è‹¥,æ™ºæ…§
    """

    def __init__(self, csv_path: Path):
        self.path = csv_path
        self.name = csv_path.stem
        self.dict_id = f"user.csv.{self.name}"
        self._index: dict[str, list[str]] = {}
        self._loaded = False
        self._entry_count = 0

    def _ensure_loaded(self):
        if self._loaded:
            return
        start = time.time()
        try:
            with open(self.path, encoding="utf-8", newline="") as f:
                reader_obj = csv.DictReader(f)
                if not reader_obj.fieldnames:
                    log.warning(f"  CSV æ— è¡¨å¤´: {self.path}")
                    self._loaded = True
                    return

                # è‡ªåŠ¨è¯†åˆ«åˆ—å
                fields = reader_obj.fieldnames
                term_col = None
                defn_col = None
                for col in fields:
                    cl = col.lower().strip()
                    if cl in ("term", "è¯æ¡", "word", "headword", "key"):
                        term_col = col
                    elif cl in ("definition", "é‡Šä¹‰", "è§£é‡Š", "meaning", "value", "def"):
                        defn_col = col

                if not term_col or not defn_col:
                    log.warning(f"  CSV ç¼ºå°‘ term/definition åˆ—: {self.path} (åˆ—: {fields})")
                    self._loaded = True
                    return

                for row in reader_obj:
                    term = (row.get(term_col) or "").strip()
                    defn = (row.get(defn_col) or "").strip()
                    if term:
                        if term not in self._index:
                            self._index[term] = []
                        self._index[term].append(defn)

            self._entry_count = len(self._index)
            elapsed = time.time() - start
            log.info(f"  CSV åŠ è½½å®Œæˆ: {self.name} ({self._entry_count} è¯æ¡, {elapsed:.1f}ç§’)")
        except Exception as e:
            log.error(f"  CSV åŠ è½½å¤±è´¥: {self.path}: {e}")
        self._loaded = True

    def lookup(self, term: str) -> list[dict]:
        self._ensure_loaded()
        results = []
        definitions = self._index.get(term, [])
        for defn in definitions:
            results.append({
                "dict_id": self.dict_id,
                "dict_name": self.name,
                "char_type": "ç”¨æˆ·è¯å…¸",
                "term": term,
                "definition": defn,
            })
        return results

    @property
    def info(self) -> dict:
        self._ensure_loaded()
        return {
            "dict_id": self.dict_id,
            "name": self.name,
            "source": f"ç”¨æˆ·è¯å…¸ (CSV): {self.path.name}",
            "entry_count": self._entry_count,
            "char_type": "ç”¨æˆ·è¯å…¸",
        }


# â”€â”€ è¯å…¸ç®¡ç†å™¨ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# æ ¼å¼æ³¨å†Œè¡¨
FORMAT_MAP = {
    ".mdx": MdxDictionary,
    ".json": JsonDictionary,
    ".csv": CsvDictionary,
}


class UserDictManager:
    """
    ç”¨æˆ·è¯å…¸ç®¡ç†å™¨

    æ‰«ææŒ‡å®šç›®å½•ä¸‹çš„è¯å…¸æ–‡ä»¶ï¼Œæä¾›ç»Ÿä¸€æŸ¥è¯¢æ¥å£ã€‚
    è¯å…¸é‡‡ç”¨å»¶è¿ŸåŠ è½½ç­–ç•¥ï¼šæ‰«ææ—¶åªè®°å½•æ–‡ä»¶è·¯å¾„ï¼Œé¦–æ¬¡æŸ¥è¯¢æ—¶æ‰çœŸæ­£åŠ è½½æ•°æ®ã€‚
    """

    def __init__(self, user_dict_dir: Path):
        self.dir = user_dict_dir
        self.dicts: list = []
        self._scan()

    def _scan(self):
        """æ‰«æç›®å½•ä¸­çš„è¯å…¸æ–‡ä»¶"""
        if not self.dir.exists():
            self.dir.mkdir(parents=True, exist_ok=True)
            # åˆ›å»º README è¯´æ˜æ–‡ä»¶
            readme = self.dir / "README.txt"
            if not readme.exists():
                readme.write_text(
                    "å°†è¯å…¸æ–‡ä»¶æ”¾å…¥æ­¤ç›®å½•ï¼Œé‡å¯æœåŠ¡å™¨åè‡ªåŠ¨åŠ è½½ã€‚\n"
                    "\n"
                    "æ”¯æŒæ ¼å¼:\n"
                    "  .mdx  â€” MDict æ ¼å¼ï¼ˆæœ€å¸¸è§ï¼Œå¤æ±‰è¯­è¯å…¸ç­‰ï¼‰\n"
                    "  .json â€” JSON æ ¼å¼ï¼ˆå¯¹è±¡æˆ–æ•°ç»„ï¼‰\n"
                    "  .csv  â€” CSV æ ¼å¼ï¼ˆéœ€å« term å’Œ definition åˆ—ï¼‰\n"
                    "\n"
                    "ç¤ºä¾‹æ–‡ä»¶å:\n"
                    "  å¤æ±‰è¯­è¯å…¸.mdx\n"
                    "  æ±‰è¯­å¤§è¯å…¸.mdx\n"
                    "  è‡ªåˆ¶æœ¯è¯­è¡¨.csv\n",
                    encoding="utf-8",
                )
            log.info(f"  ç”¨æˆ·è¯å…¸ç›®å½•å·²åˆ›å»º: {self.dir}")
            return

        count = 0
        for path in sorted(self.dir.iterdir()):
            ext = path.suffix.lower()
            if ext in FORMAT_MAP and path.is_file():
                dict_class = FORMAT_MAP[ext]
                d = dict_class(path)
                self.dicts.append(d)
                count += 1
                log.info(f"  å‘ç°ç”¨æˆ·è¯å…¸: {path.name} ({ext})")

        if count:
            log.info(f"  ç”¨æˆ·è¯å…¸å…± {count} éƒ¨ï¼ˆå»¶è¿ŸåŠ è½½ï¼Œé¦–æ¬¡æŸ¥è¯¢æ—¶è¯»å–ï¼‰")
        else:
            log.info(f"  ç”¨æˆ·è¯å…¸ç›®å½•ä¸ºç©º: {self.dir}")

    def lookup(self, term: str) -> list[dict]:
        """åœ¨æ‰€æœ‰ç”¨æˆ·è¯å…¸ä¸­æŸ¥è¯¢"""
        results = []
        for d in self.dicts:
            results.extend(d.lookup(term))
        return results

    def list_dicts(self) -> list[dict]:
        """åˆ—å‡ºæ‰€æœ‰ç”¨æˆ·è¯å…¸ä¿¡æ¯"""
        return [d.info for d in self.dicts]

    def reload(self):
        """é‡æ–°æ‰«æç›®å½•ï¼ˆçƒ­é‡è½½ï¼‰"""
        self.dicts.clear()
        self._scan()
