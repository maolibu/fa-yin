"""
CBETA è‡ªåŠ¨æ ¡å¯¹è„šæœ¬
å°†æœ¬åœ° ETL è¾“å‡ºä¸ CBETA å®˜æ–¹åœ¨çº¿ API æ–‡æœ¬é€å­—å¯¹æ¯”ï¼Œå‘ç°é”™æ¼ã€‚

ç”¨æ³•ï¼š
    python tools/verify_against_cbeta.py T0251           # æ ¡å¯¹å•éƒ¨ç»
    python tools/verify_against_cbeta.py T0001 --juan 1   # æ ¡å¯¹æŒ‡å®šå·
    python tools/verify_against_cbeta.py --all            # æ ¡å¯¹å…¨éƒ¨å·²è½¬æ¢ç»å…¸

CBETA API ç«¯ç‚¹ï¼š
    https://cbdata.dila.edu.tw/stable/juans?work={ç»å·}&juan={å·å·}
"""

import argparse
import difflib
import json
import os
import re
import sqlite3
import sys
import time
import urllib.request
import urllib.error
from pathlib import Path

# ============================================================
# é…ç½®
# ============================================================
ETL_DIR = Path(__file__).resolve().parent.parent
PROJECT_ROOT = ETL_DIR.parent
DB_PATH = ETL_DIR / "output" / "cbeta.db"
REPORT_DIR = ETL_DIR / "output" / "verify_reports"

CBETA_API_BASE = "https://cbdata.dila.edu.tw/stable/juans"
REQUEST_DELAY = 5.0  # è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰ï¼Œé¿å…ç»™ CBETA æœåŠ¡å™¨é€ æˆå‹åŠ›ï¼ˆå…¨é‡æ ¡å¯¹å»ºè®® 5 ç§’ï¼‰


# ============================================================
# ä» CBETA API è·å–å‚è€ƒæ–‡æœ¬
# ============================================================
def fetch_cbeta_html(work_id, juan_num):
    """
    è°ƒç”¨ CBETA API è·å–æŒ‡å®šç»å·çš„ HTML å†…å®¹ã€‚
    è¿”å› HTML å­—ç¬¦ä¸²ï¼Œæˆ– Noneï¼ˆå¤±è´¥æ—¶ï¼‰ã€‚
    """
    import ssl
    url = f"{CBETA_API_BASE}?work={work_id}&juan={juan_num}"
    try:
        req = urllib.request.Request(url)
        req.add_header("User-Agent", "FaYin-ETL-Verify/1.0 (Buddhist Digital Humanities)")
        try:
            with urllib.request.urlopen(req, timeout=30) as resp:
                data = json.loads(resp.read().decode("utf-8"))
        except urllib.error.URLError as e:
            if "CERTIFICATE_VERIFY_FAILED" in str(e):
                # SSL è¯ä¹¦é—®é¢˜ï¼ˆconda ç¯å¢ƒå¸¸è§ï¼‰ï¼Œå›é€€åˆ°ä¸éªŒè¯
                ctx = ssl._create_unverified_context()
                with urllib.request.urlopen(req, timeout=30, context=ctx) as resp:
                    data = json.loads(resp.read().decode("utf-8"))
            else:
                raise
        results = data.get("results", [])
        if results:
            return results[0]
        return None
    except (urllib.error.URLError, urllib.error.HTTPError, json.JSONDecodeError) as e:
        print(f"    âš ï¸ API è¯·æ±‚å¤±è´¥ ({work_id} å·{juan_num}): {e}")
        return None


# ============================================================
# æ–‡æœ¬è§„èŒƒåŒ–ï¼šå»æ ‡ç­¾ã€å»æ ‡ç‚¹ã€å»ç©ºç™½
# ============================================================
def strip_html_tags(html):
    """å»é™¤æ‰€æœ‰ HTML æ ‡ç­¾ï¼Œä¿ç•™æ–‡æœ¬å†…å®¹"""
    return re.sub(r"<[^>]+>", "", html)


def preprocess_cbeta_html(html):
    """
    é¢„å¤„ç† CBETA API è¿”å›çš„ HTMLï¼š
    åªä¿ç•™ <div id='body'...>...</div> ä¸­çš„æ­£æ–‡ï¼Œ
    å»é™¤ <head>, æ ¡æ³¨ (<div id='back'>), ç‰ˆæƒå£°æ˜ç­‰ã€‚
    """
    # ç”¨å­—ç¬¦ä¸²æŸ¥æ‰¾å®šä½ body divï¼ˆä¸ä¾èµ–æ¢è¡Œ/ç©ºæ ¼æ ¼å¼ï¼‰
    body_start = html.find("<div id='body'")
    if body_start == -1:
        # å…¼å®¹åŒå¼•å·
        body_start = html.find('<div id="body"')
    if body_start != -1:
        # è·³è¿‡ <div id='body'...> å¼€æ ‡ç­¾
        tag_end = html.find(">", body_start)
        if tag_end != -1:
            html = html[tag_end + 1:]

    # æˆªæ–­ï¼šå»æ‰ back åŒºå—åŠä¹‹åçš„å†…å®¹
    for marker in ["<div id='back'>", '<div id="back">', "<div id='back'",
                    "<div id='cbeta-copyright'>", '<div id="cbeta-copyright">']:
        pos = html.find(marker)
        if pos != -1:
            html = html[:pos]
            break

    # å» noteAnchor é“¾æ¥ï¼ˆæ ¡æ³¨å¼•ç”¨æ ‡è®°ï¼‰
    html = re.sub(r"<a class=['\"]noteAnchor['\"][^>]*>.*?</a>", "", html, flags=re.DOTALL)
    return html


def normalize_for_compare(text):
    """
    è§„èŒƒåŒ–æ–‡æœ¬ç”¨äºå¯¹æ¯”ï¼š
    1. å»é™¤æ‰€æœ‰ HTML æ ‡ç­¾
    2. å»é™¤ CBETA æ ‡ç‚¹
    3. å»é™¤ç©ºç™½å­—ç¬¦
    4. å»é™¤è¡Œå·æ ‡è®°
    5. å»é™¤ç¼–å·è¡Œ
    """
    # å» HTML æ ‡ç­¾
    text = strip_html_tags(text)

    # è§£ç  HTML å®ä½“ï¼ˆå¦‚ &nbsp; â†’ ç©ºæ ¼ï¼‰
    import html as html_module
    text = html_module.unescape(text)

    # å»ç¼–å·è¡Œï¼ˆå¦‚ "No. 251 [Nos. 250, 252-255, 257]"ï¼‰
    # ä¹Ÿå¤„ç† [cf. No. 223] æ ¼å¼ï¼ˆäº¤å‰å¼•ç”¨ï¼‰
    text = re.sub(r"\[cf\.\s*No\.\s*[^\]]+\]", "", text)
    text = re.sub(r"No\.\s*\d+\s*\[Nos?\.\s*[^\]]+\]", "", text)
    text = re.sub(r"No\.\s*\d+", "", text)

    # æ³¨æ„ï¼šå’’è¯­ä¸­çš„ CBETA æ–­å¥ç¼–å·ï¼ˆä¸€ã€äºŒã€ä¸‰...ï¼‰ä¸åšæ¸…é™¤ï¼Œ
    # å› ä¸ºä¸­æ–‡æ•°å­—ä¹Ÿå‡ºç°åœ¨æ­£æ–‡ä¸­ï¼Œæ— æ³•å®‰å…¨åŒºåˆ†ã€‚è¿™ç±»å·®å¼‚å±äºå¯æ¥å—çš„æ ¼å¼å·®å¼‚ã€‚

    # å»è¡Œå·å’Œé¡µé¢ IDï¼ˆè¦†ç›–æ‰€æœ‰è—ç»æ ¼å¼ï¼‰
    # å®Œæ•´æ ¼å¼ï¼šT08n0251_p0848a01, A098n1267_p0123b05
    text = re.sub(r"[A-Z]+\d+n\d+_p\d*[a-c]?\d*", "", text)
    # ç®€çŸ­é¡µé¢ IDï¼ˆAPI æœ‰æ—¶ä»…è¾“å‡º A098n1267_p ä¸å¸¦è¡Œå·ï¼‰
    text = re.sub(r"[A-Z]+\d+n\d+_p", "", text)
    # æ—§æ ¼å¼è¡Œå·
    text = re.sub(r"\d{4}[a-c]\d{2}", "", text)

    # å» CBETA æ ‡ç‚¹ç¬¦å·ï¼ˆå…¨é¢è¦†ç›–ï¼‰
    punctuation = (
        "ï¼Œã€‚ã€ï¼›ï¼šï¼ï¼Ÿã€Œã€ã€ã€ï¼ˆï¼‰ã€”ã€•ã€ã€‘"
        "â€¦â€¦â€”â”€ã€€"
        "ï¼Â·"
        ",.:;!?\"'()[]{}|/\\"
        "ï¼Šï¼"
        "ã€ˆã€‰ã€Šã€‹"
        "ï¼"
    )
    for p in punctuation:
        text = text.replace(p, "")

    # å»é™¤ç©ºç™½
    text = re.sub(r"\s+", "", text)

    return text


# ============================================================
# å¯¹æ¯”ä¸¤æ®µæ–‡æœ¬
# ============================================================
def compare_texts(local_text, cbeta_text, context_size=10):
    """
    å¯¹æ¯”ä¸¤æ®µè§„èŒƒåŒ–åçš„æ–‡æœ¬ã€‚
    è¿”å›:
        match_ratio: åŒ¹é…ç‡ (0.0 ~ 1.0)
        diffs: å·®å¼‚åˆ—è¡¨ [(type, position, local_snippet, cbeta_snippet), ...]
    """
    matcher = difflib.SequenceMatcher(None, local_text, cbeta_text)
    match_ratio = matcher.ratio()

    diffs = []
    for tag, i1, i2, j1, j2 in matcher.get_opcodes():
        if tag == "equal":
            continue

        # è·å–ä¸Šä¸‹æ–‡
        ctx_start_local = max(0, i1 - context_size)
        ctx_end_local = min(len(local_text), i2 + context_size)
        ctx_start_cbeta = max(0, j1 - context_size)
        ctx_end_cbeta = min(len(cbeta_text), j2 + context_size)

        local_context = (
            local_text[ctx_start_local:i1]
            + "ã€" + local_text[i1:i2] + "ã€‘"
            + local_text[i2:ctx_end_local]
        )
        cbeta_context = (
            cbeta_text[ctx_start_cbeta:j1]
            + "ã€" + cbeta_text[j1:j2] + "ã€‘"
            + cbeta_text[j2:ctx_end_cbeta]
        )

        diffs.append({
            "type": tag,
            "position": i1,
            "local_chars": local_text[i1:i2],
            "cbeta_chars": cbeta_text[j1:j2],
            "local_context": local_context,
            "cbeta_context": cbeta_context,
        })

    return match_ratio, diffs


# ============================================================
# æ ¡å¯¹å•å·
# ============================================================
def verify_juan(conn, sutra_id, juan_num):
    """
    æ ¡å¯¹å•å·ï¼šä»æ•°æ®åº“å–æœ¬åœ°æ–‡æœ¬ï¼Œä» API å– CBETA æ–‡æœ¬ï¼Œåšå¯¹æ¯”ã€‚
    è¿”å› (match_ratio, diffs, local_len, cbeta_len) æˆ– Noneã€‚
    """
    # è·å–æœ¬åœ°æ–‡æœ¬
    row = conn.execute(
        "SELECT plain_text FROM content WHERE sutra_id = ? AND juan = ?",
        (sutra_id, juan_num),
    ).fetchone()
    if not row:
        print(f"    âš ï¸ æœ¬åœ°æ•°æ®åº“æ—  {sutra_id} å·{juan_num}")
        return None

    local_raw = row[0]

    # ä» CBETA API è·å–å‚è€ƒæ–‡æœ¬
    # éœ€è¦å°† sutra_id (å¦‚ T0251) è½¬æ¢ä¸º API æ ¼å¼
    # API work å‚æ•°ç›´æ¥ä½¿ç”¨ sutra_id å³å¯
    cbeta_html = fetch_cbeta_html(sutra_id, juan_num)
    if cbeta_html is None:
        return None

    # è§„èŒƒåŒ–
    local_norm = normalize_for_compare(local_raw)
    cbeta_norm = normalize_for_compare(preprocess_cbeta_html(cbeta_html))

    # å¯¹æ¯”
    match_ratio, diffs = compare_texts(local_norm, cbeta_norm)

    return match_ratio, diffs, len(local_norm), len(cbeta_norm)


# ============================================================
# æ ¡å¯¹æ•´éƒ¨ç»
# ============================================================
def verify_sutra(conn, sutra_id, juan_filter=None):
    """æ ¡å¯¹æ•´éƒ¨ç»ï¼ˆæˆ–æŒ‡å®šå·ï¼‰"""
    # è·å–å·åˆ—è¡¨
    if juan_filter is not None:
        rows = conn.execute(
            "SELECT juan FROM content WHERE sutra_id = ? AND juan = ? ORDER BY juan",
            (sutra_id, juan_filter),
        ).fetchall()
    else:
        rows = conn.execute(
            "SELECT juan FROM content WHERE sutra_id = ? ORDER BY juan",
            (sutra_id,),
        ).fetchall()

    if not rows:
        print(f"âŒ æ•°æ®åº“ä¸­æ‰¾ä¸åˆ° {sutra_id}")
        return None

    # è·å–ç»å
    cat = conn.execute(
        "SELECT title FROM catalog WHERE sutra_id = ?", (sutra_id,)
    ).fetchone()
    title = cat[0] if cat else sutra_id

    print(f"\n{'='*60}")
    print(f"ğŸ“– {sutra_id} {title} ({len(rows)} å·)")
    print(f"{'='*60}")

    results = []
    for (juan_num,) in rows:
        print(f"  å· {juan_num:>3d} ...", end=" ", flush=True)
        result = verify_juan(conn, sutra_id, juan_num)

        if result is None:
            print("âš ï¸ è·³è¿‡")
            continue

        match_ratio, diffs, local_len, cbeta_len = result

        # æ˜¾ç¤ºç»“æœ
        if match_ratio >= 0.99:
            icon = "âœ…"
        elif match_ratio >= 0.95:
            icon = "ğŸŸ¡"
        else:
            icon = "âŒ"

        print(
            f"{icon} åŒ¹é…ç‡ {match_ratio:.1%}  "
            f"(æœ¬åœ° {local_len} å­— / CBETA {cbeta_len} å­—, "
            f"å·®å¼‚ {len(diffs)} å¤„)"
        )

        # æ˜¾ç¤ºå‰ 5 ä¸ªå·®å¼‚
        for i, d in enumerate(diffs[:5]):
            tag_label = {
                "replace": "æ›¿æ¢",
                "delete": "æœ¬åœ°å¤šä½™",
                "insert": "æœ¬åœ°ç¼ºå°‘",
            }.get(d["type"], d["type"])
            print(f"    {i+1}. [{tag_label}] ä½ç½® {d['position']}")
            if d["local_chars"]:
                print(f"       æœ¬åœ°: ...{d['local_context']}...")
            if d["cbeta_chars"]:
                print(f"       CBETA: ...{d['cbeta_context']}...")

        if len(diffs) > 5:
            print(f"    ... è¿˜æœ‰ {len(diffs) - 5} å¤„å·®å¼‚")

        results.append({
            "sutra_id": sutra_id,
            "juan": juan_num,
            "match_ratio": match_ratio,
            "local_len": local_len,
            "cbeta_len": cbeta_len,
            "diff_count": len(diffs),
            "diffs": diffs,
        })

        # è¯·æ±‚é—´éš”
        time.sleep(REQUEST_DELAY)

    return results


# ============================================================
# ä¿å­˜æŠ¥å‘Š
# ============================================================
def save_report(all_results, report_path):
    """å°†æ ¡å¯¹ç»“æœä¿å­˜ä¸º JSON æŠ¥å‘Š"""
    os.makedirs(report_path.parent, exist_ok=True)

    # æ±‡æ€»ç»Ÿè®¡
    total_juans = sum(len(r) for r in all_results if r)
    total_diffs = sum(
        sum(j["diff_count"] for j in r)
        for r in all_results if r
    )
    avg_ratio = 0
    ratios = [j["match_ratio"] for r in all_results if r for j in r]
    if ratios:
        avg_ratio = sum(ratios) / len(ratios)

    report = {
        "generated_at": time.strftime("%Y-%m-%d %H:%M:%S"),
        "summary": {
            "total_juans": total_juans,
            "total_diffs": total_diffs,
            "avg_match_ratio": round(avg_ratio, 4),
        },
        "details": [j for r in all_results if r for j in r],
    }

    with open(report_path, "w", encoding="utf-8") as f:
        json.dump(report, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_path}")


# ============================================================
# ä¸»ç¨‹åº
# ============================================================
def main():
    parser = argparse.ArgumentParser(description="CBETA è‡ªåŠ¨æ ¡å¯¹å·¥å…·")
    parser.add_argument(
        "sutra_id", nargs="?", default=None,
        help="ç»å·ï¼ˆå¦‚ T0251ï¼‰",
    )
    parser.add_argument("--juan", type=int, help="æŒ‡å®šå·å·")
    parser.add_argument("--all", action="store_true", help="æ ¡å¯¹å…¨éƒ¨å·²è½¬æ¢ç»å…¸")
    parser.add_argument(
        "--report", type=str, default=None,
        help="ä¿å­˜ JSON æŠ¥å‘Šçš„è·¯å¾„ï¼ˆé»˜è®¤: output/verify_reports/verify_<ç»å·>.jsonï¼‰",
    )
    args = parser.parse_args()

    if not DB_PATH.exists():
        print(f"âŒ æ•°æ®åº“ä¸å­˜åœ¨: {DB_PATH}")
        print("è¯·å…ˆè¿è¡Œ ETL è½¬æ¢è„šæœ¬")
        return

    conn = sqlite3.connect(str(DB_PATH))

    all_results = []

    if args.all:
        # æ ¡å¯¹å…¨éƒ¨
        rows = conn.execute(
            "SELECT DISTINCT sutra_id FROM catalog ORDER BY sutra_id"
        ).fetchall()
        print(f"ğŸ“š å°†æ ¡å¯¹ {len(rows)} éƒ¨å·²è½¬æ¢ç»å…¸")
        for (sutra_id,) in rows:
            result = verify_sutra(conn, sutra_id)
            all_results.append(result)

        report_path = Path(args.report) if args.report else REPORT_DIR / "verify_all.json"

    elif args.sutra_id:
        # æ ¡å¯¹å•éƒ¨ç»
        result = verify_sutra(conn, args.sutra_id, args.juan)
        all_results.append(result)

        report_path = (
            Path(args.report) if args.report
            else REPORT_DIR / f"verify_{args.sutra_id}.json"
        )

    else:
        parser.print_help()
        conn.close()
        return

    # æ±‡æ€»
    ratios = [j["match_ratio"] for r in all_results if r for j in r]
    total_diffs = sum(j["diff_count"] for r in all_results if r for j in r)

    print(f"\n{'='*60}")
    print("ğŸ“Š æ ¡å¯¹æ±‡æ€»")
    print(f"{'='*60}")
    print(f"  æ ¡å¯¹å·æ•°: {len(ratios)}")
    if ratios:
        print(f"  å¹³å‡åŒ¹é…ç‡: {sum(ratios)/len(ratios):.1%}")
        print(f"  æœ€ä½åŒ¹é…ç‡: {min(ratios):.1%}")
        print(f"  æ€»å·®å¼‚æ•°: {total_diffs}")

    # ä¿å­˜æŠ¥å‘Š
    save_report(all_results, report_path)

    conn.close()


if __name__ == "__main__":
    main()
