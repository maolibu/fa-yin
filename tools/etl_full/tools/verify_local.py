"""
æœ¬åœ°æ ‡ç­¾éªŒè¯è„šæœ¬ â€” XML æº vs æ•°æ®åº“å¯¹æ¯”

å¯¹æ¯” XML æºæ–‡ä»¶çš„ç»“æ„åŒ–æ•°æ®ï¼ˆæ³¨é‡Šã€æ ¡å‹˜ã€ç›®å½•ï¼‰æ•°é‡ä¸æ•°æ®åº“è¡¨è¡Œæ•°ã€‚
ç»Ÿè®¡é€»è¾‘ä¸ ETL (etl_xml_to_db.py) ä¿æŒä¸€è‡´ï¼š
  - æ ¡å‹˜ï¼šä¼˜å…ˆæŸ¥ <back>ï¼Œä¸å­˜åœ¨åˆ™æŸ¥ <body>ï¼ˆåŒ¹é… extract_apparatusï¼‰
  - æ³¨é‡Šï¼šè¿‡æ»¤å†…å®¹ä¸ºç©ºçš„ <note>ï¼ˆåŒ¹é… extract_notes çš„ get_text_recursive + stripï¼‰
  - ç›®å½•ï¼šç»Ÿè®¡ <cb:mulu>ï¼ˆåŒ¹é… extract_tocï¼‰

ç”¨æ³•ï¼š
    python tools/verify_local.py T0001          # éªŒè¯å•éƒ¨ç»
    python tools/verify_local.py --canon A       # éªŒè¯æ•´ä¸ªè—ç»
    python tools/verify_local.py --all           # éªŒè¯å…¨éƒ¨

è¾“å‡ºï¼š
    output/verify_local_report.json
"""

import argparse
import glob
import json
import os
import re
import sqlite3
import sys
import time
import xml.etree.ElementTree as ET
from pathlib import Path

# å¤ç”¨ ETL çš„é…ç½®
ETL_DIR = Path(__file__).resolve().parent.parent
PROJECT_ROOT = ETL_DIR.parent
XML_BASE = PROJECT_ROOT / "01_data_raw" / "cbeta_xml_p5"
DB_PATH = ETL_DIR / "output" / "cbeta.db"
OUTPUT_DIR = ETL_DIR / "output"

# XML å‘½åç©ºé—´
TEI_NS = "http://www.tei-c.org/ns/1.0"
CB_NS = "http://www.cbeta.org/ns/1.0"

# æ·»åŠ æ¨¡å—æœç´¢è·¯å¾„ï¼ˆå¤ç”¨ gaiji_mapï¼‰
# tools/.. (10_etl)
sys.path.insert(0, str(Path(__file__).resolve().parent.parent))
import gaiji_map

# ä¸ ETL ä¸€è‡´çš„è·³è¿‡æ ‡ç­¾
SKIP_TAGS_TEXT = {"note", "rdg", "anchor", "back", "mulu", "charDecl", "teiHeader"}
SELF_CLOSING = {"lb", "pb", "milestone"}


def _local_tag(element):
    """è·å–å…ƒç´ çš„æœ¬åœ°åï¼ˆå»é™¤å‘½åç©ºé—´ï¼‰"""
    tag = element.tag
    if "}" in tag:
        return tag.split("}")[1]
    return tag


def get_text_recursive(element):
    """é€’å½’æå–å…ƒç´ çº¯æ–‡æœ¬ï¼ˆä¸ ETL é€»è¾‘å®Œå…¨ä¸€è‡´ï¼Œç”¨äºåˆ¤æ–­æ³¨é‡Šæ˜¯å¦ä¸ºç©ºï¼‰"""
    parts = []
    if element.text:
        parts.append(element.text)

    for child in element:
        tag = _local_tag(child)
        if tag == "g":
            # Gaiji ç¼ºå­—å¤„ç†
            ref = child.get("ref", "")
            cb_id = ref.lstrip("#")
            resolved = gaiji_map.resolve(cb_id)
            parts.append(resolved)
        elif tag == "lem":
            # æ ¡å‹˜æ­£æ–‡ï¼šå–åº•æœ¬
            parts.append(get_text_recursive(child))
        elif tag == "app":
            # æ ¡å‹˜æ®µï¼šé€’å½’è¿›å…¥ï¼ˆä¼šç¢°åˆ° lem å’Œ rdgï¼‰
            parts.append(get_text_recursive(child))
        elif tag in SKIP_TAGS_TEXT:
            # è·³è¿‡ä¸è¾“å‡ºï¼ˆnote, rdg, anchor, back, mulu, charDecl, teiHeaderï¼‰
            pass
        elif tag == "space":
            quantity = child.get("quantity", "1")
            try:
                n = int(quantity)
            except ValueError:
                n = 1
            parts.append("ã€€" * n)
        elif tag == "caesura":
            # åˆé¢‚åœé¡¿
            parts.append("ã€€")
        elif tag == "choice":
            # <choice> åŒ…å« <sic>+<corr> æˆ– <orig>+<reg>ï¼šé€’å½’è¿›å…¥
            # ï¼ˆå†…éƒ¨ä¼šå‘½ä¸­ corr/reg ä¿ç•™ã€sic/orig è·³è¿‡ï¼‰
            parts.append(get_text_recursive(child))
        elif tag in ("sic", "orig"):
            # åŸæ–‡é”™è¯¯/åŸå§‹å½¢å¼ï¼šçº¯æ–‡æœ¬ä¸­è·³è¿‡ï¼ˆåªä¿ç•™ corr/regï¼‰
            pass
        elif tag in ("corr", "reg"):
            # æ ¡æ­£/æ­£åˆ™åŒ–å½¢å¼ï¼šä¿ç•™
            parts.append(get_text_recursive(child))
        elif tag in SELF_CLOSING:
            # lb, pb, milestone ç­‰è‡ªå…³é—­æ— æ–‡æœ¬
            pass
        else:
            # æ‰€æœ‰å…¶ä½™å…ƒç´ é€’å½’æå–çº¯æ–‡æœ¬
            parts.append(get_text_recursive(child))

        if child.tail:
            parts.append(child.tail)

    return "".join(parts)


def scan_xml(xml_files):
    """æ‰«æ XML æ–‡ä»¶ï¼Œç»Ÿè®¡å…³é”®æ ‡ç­¾æ•°é‡ï¼ˆä¸ ETL é€»è¾‘å¯¹é½ï¼‰"""
    juan_set = set()  # ç”¨ set å»é‡å·å·ï¼ˆè·¨å†Œç»æ–‡åŒä¸€å·å·åªç®—ä¸€æ¬¡ï¼‰
    counts = {
        "juans": 0,       # æœ€åä» juan_set è®¡ç®—
        "notes": 0,       # éç©º <note> æ•°é‡ï¼ˆåŒ¹é… extract_notesï¼‰
        "apps": 0,        # <app> æ•°é‡ï¼ˆåŒ¹é… extract_apparatusï¼‰
        "toc_entries": 0, # <cb:mulu> æ•°é‡ï¼ˆåŒ¹é… extract_tocï¼‰
    }

    for xml_path in xml_files:
        try:
            # ä½¿ç”¨ fromstring æ›¿ä»£ parseï¼Œé¿å… IO æŒ‚èµ·
            with open(str(xml_path), "r", encoding="utf-8") as f:
                content = f.read()
            root = ET.fromstring(content)
            body = root.find(f".//{{{TEI_NS}}}body")
            if body is None:
                continue

            # --- å·æ•°ï¼šä» milestone ç»Ÿè®¡ï¼Œç”¨ set å»é‡ï¼ˆåŒ¹é… ETL çš„ extract_juansï¼‰ ---
            # extract_juans é€»è¾‘ï¼š
            #   - len(milestones) <= 1ï¼šæ•´ä¸ª body å½’å…¥è¯¥ milestone çš„å·å·ï¼ˆæ— åˆ™é»˜è®¤ 1ï¼‰
            #   - len(milestones) > 1ï¼šæŒ‰ milestone åˆ‡åˆ†ï¼Œfirst_n != 1 æ—¶å‰å¯¼å†…å®¹å½’å…¥é»˜è®¤å· 1
            milestones = [e for e in body.iter()
                          if _local_tag(e) == "milestone" and e.get("unit") == "juan"]
            if milestones:
                if len(milestones) == 1:
                    # å• milestoneï¼šæ•´ä¸ª body å½’å…¥è¯¥å·å·ï¼ˆä¸ ETL ä¸€è‡´ï¼‰
                    n = milestones[0].get("n", "1")
                    try:
                        juan_set.add(int(n))
                    except ValueError:
                        juan_set.add(1)
                else:
                    # å¤š milestoneï¼šfirst_n != 1 æ—¶å‰å¯¼å†…å®¹å½’å…¥é»˜è®¤å· 1
                    first_n = milestones[0].get("n", "1")
                    try:
                        if int(first_n) != 1:
                            juan_set.add(1)  # å‰å¯¼å†…å®¹è¢«åˆ†é…åˆ°é»˜è®¤å· 1
                    except ValueError:
                        pass
                    for m in milestones:
                        n = m.get("n", "1")
                        try:
                            juan_set.add(int(n))
                        except ValueError:
                            pass
            else:
                juan_set.add(1)  # æ—  milestone çš„å•å·ç»

            # --- æ³¨é‡Š + ç›®å½•ï¼šä» body ä¸­ç»Ÿè®¡ï¼ˆåŒ¹é… extract_notes / extract_tocï¼‰---
            for elem in body.iter():
                tag = _local_tag(elem)
                if tag == "note":
                    # åŒ¹é… ETLï¼šåªç»Ÿè®¡å†…å®¹éç©ºçš„æ³¨é‡Š
                    content_text = get_text_recursive(elem).strip()
                    if content_text:
                        counts["notes"] += 1
                elif tag == "mulu":
                    counts["toc_entries"] += 1

            # --- æ ¡å‹˜ï¼šä¼˜å…ˆ backï¼Œé€€è€Œ bodyï¼ˆåŒ¹é… extract_apparatusï¼‰---
            search_root = root.find(f".//{{{TEI_NS}}}back")
            if search_root is None:
                search_root = body
            for elem in search_root.iter():
                tag = _local_tag(elem)
                if tag == "app":
                    # åŒ¹é… ETLï¼šæœ‰ lem æ–‡æœ¬æˆ–æœ‰ rdg å­å…ƒç´ å³ç®—
                    lem_text = ""
                    readings = []
                    for child in elem:
                        ct = _local_tag(child)
                        if ct == "lem":
                            lem_text = get_text_recursive(child).strip()
                        elif ct == "rdg":
                            readings.append(child)
                    if lem_text or readings:
                        counts["apps"] += 1

        except Exception as e:
            print(f"  âš ï¸ XML è§£æå¤±è´¥ {os.path.basename(xml_path)}: {e}")

    counts["juans"] = len(juan_set)
    return counts


def scan_db(conn, sutra_id):
    """ä»æ•°æ®åº“æŸ¥è¯¢å„é¡¹è®¡æ•°"""
    counts = {}

    # å·æ•°
    cur = conn.execute("SELECT COUNT(*) FROM content WHERE sutra_id=?", (sutra_id,))
    counts["juans"] = cur.fetchone()[0]

    # notes è¡¨
    cur = conn.execute("SELECT COUNT(*) FROM notes WHERE sutra_id=?", (sutra_id,))
    counts["notes"] = cur.fetchone()[0]

    # apparatus è¡¨
    cur = conn.execute("SELECT COUNT(*) FROM apparatus WHERE sutra_id=?", (sutra_id,))
    counts["apps"] = cur.fetchone()[0]

    # toc è¡¨
    cur = conn.execute("SELECT COUNT(*) FROM toc WHERE sutra_id=?", (sutra_id,))
    counts["toc_entries"] = cur.fetchone()[0]

    return counts


def find_sutra_files(sutra_id):
    """æ ¹æ® sutra_id æ‰¾åˆ° P5 XML æ–‡ä»¶"""
    # æƒ…å†µ1ï¼šsutra_id åŒ…å« 'n'ï¼Œè¯´æ˜ä¿ç•™äº†å®Œæ•´çš„ xml_id æ ¼å¼
    # ï¼ˆå¦‚ J01nA042 â€” å˜‰å…´è—å¤§å†™ç¼–å·ï¼ŒETL æ­£åˆ™æœªèƒ½è§£æï¼‰
    if "n" in sutra_id:
        # æå–è—ç»ä»£ç ç”¨äºå®šä½ç›®å½•
        m = re.match(r"([A-Z]+)", sutra_id)
        if m:
            canon = m.group(1)
            pattern = str(XML_BASE / canon / "*" / f"{sutra_id}.xml")
            files = sorted(glob.glob(pattern))
            if files:
                return files

    # æƒ…å†µ2ï¼šæ ‡å‡†æ ¼å¼å¦‚ T0001, Ba001, GA0037
    match = re.match(r"([A-Z]+)([a-z]?\d+[a-z]?\d*)", sutra_id)
    if not match:
        return []
    canon = match.group(1)
    sutra_no = match.group(2)
    # å…ˆç²¾ç¡®åŒ¹é…ï¼ˆå¦‚ T*n0001.xmlï¼‰
    pattern = str(XML_BASE / canon / "*" / f"{canon}*n{sutra_no}.xml")
    files = sorted(glob.glob(pattern))
    if not files:
        # å›é€€ï¼šåŒ¹é…å¸¦å¤§å†™åç¼€çš„æ–‡ä»¶ï¼ˆå¦‚ T02n0150A.xml, T02n0150B.xmlï¼‰
        pattern = str(XML_BASE / canon / "*" / f"{canon}*n{sutra_no}[A-Z].xml")
        files = sorted(glob.glob(pattern))
    return files


def verify_sutra(sutra_id, conn):
    """éªŒè¯å•éƒ¨ç»ï¼Œè¿”å›ç»“æœ dict"""
    xml_files = find_sutra_files(sutra_id)
    if not xml_files:
        return {"sutra_id": sutra_id, "status": "skip", "reason": "æ—  XML æ–‡ä»¶"}

    xml = scan_xml(xml_files)
    db = scan_db(conn, sutra_id)

    # æ¯”è¾ƒç»“æœï¼ˆå…¨éƒ¨è¦æ±‚ç²¾ç¡®åŒ¹é…ï¼‰
    checks = []
    all_pass = True

    for field, label in [
        ("juans", "å·æ•°"), ("notes", "æ³¨é‡Š"),
        ("apps", "æ ¡å‹˜"), ("toc_entries", "ç›®å½•"),
    ]:
        xml_val = xml[field]
        db_val = db[field]
        match = xml_val == db_val
        checks.append({"item": label, "xml": xml_val, "db": db_val, "pass": match})
        if not match:
            all_pass = False

    # æ‰“å°ç»“æœ
    status = "âœ…" if all_pass else "âŒ"
    items_str = " | ".join(
        f"{c['item']}={'âœ…' if c['pass'] else 'âŒ'}{c['xml']}â†’{c['db']}"
        for c in checks
    )
    print(f"  {status} {sutra_id}: {items_str}")

    return {
        "sutra_id": sutra_id,
        "status": "pass" if all_pass else "fail",
        "checks": checks,
    }


def main():
    parser = argparse.ArgumentParser(description="æœ¬åœ°æ ‡ç­¾éªŒè¯ï¼šXML vs æ•°æ®åº“")
    parser.add_argument("target", nargs="?", default=None, help="ç»å·æˆ–è—ç»ä»£ç ")
    parser.add_argument("--canon", type=str, help="æŒ‰è—ç»éªŒè¯ï¼ˆå¦‚ Aï¼‰")
    parser.add_argument("--all", action="store_true", help="éªŒè¯å…¨éƒ¨å·²è½¬æ¢ç»å…¸")
    args = parser.parse_args()

    conn = sqlite3.connect(str(DB_PATH))
    gaiji_map.load_gaiji_map()

    # ç¡®å®šè¦éªŒè¯çš„ç»å…¸
    sutra_ids = []
    if args.all:
        cur = conn.execute("SELECT sutra_id FROM catalog ORDER BY sutra_id")
        sutra_ids = [row[0] for row in cur]
    elif args.canon:
        cur = conn.execute(
            "SELECT sutra_id FROM catalog WHERE canon=? ORDER BY sutra_id",
            (args.canon,),
        )
        sutra_ids = [row[0] for row in cur]
    elif args.target:
        sutra_ids = [args.target]
    else:
        parser.print_help()
        return

    print(f"ğŸ“‹ éªŒè¯ {len(sutra_ids)} éƒ¨ç»å…¸")
    print()

    results = []
    passed = failed = skipped = 0
    start = time.time()

    for sid in sutra_ids:
        r = verify_sutra(sid, conn)
        results.append(r)
        if r["status"] == "pass":
            passed += 1
        elif r["status"] == "fail":
            failed += 1
        else:
            skipped += 1

    elapsed = time.time() - start
    print()
    print("=" * 50)
    print(f"âœ… é€šè¿‡: {passed}  âŒ ä¸ä¸€è‡´: {failed}  â­ï¸ è·³è¿‡: {skipped}")
    print(f"â±ï¸ è€—æ—¶: {elapsed:.1f} ç§’")

    # ä¿å­˜æŠ¥å‘Š
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    report_path = OUTPUT_DIR / "verify_local_report.json"
    report = {
        "total": len(results),
        "passed": passed,
        "failed": failed,
        "skipped": skipped,
        "elapsed_seconds": round(elapsed, 1),
        "results": results,
    }
    with open(report_path, "w", encoding="utf-8") as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    print(f"ğŸ“„ æŠ¥å‘Š: {report_path}")

    conn.close()


if __name__ == "__main__":
    main()
