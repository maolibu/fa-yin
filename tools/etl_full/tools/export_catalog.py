"""
ç»¼åˆç›®å½•å¯¼å‡ºå·¥å…· â€” ä» cbeta.db + cbeta_nav.db ç”Ÿæˆå®Œæ•´ç›®å½• CSV

ç”Ÿæˆå†…å®¹ï¼š
  1. catalog_full.csv â€” ä¸»ç›®å½•ï¼ˆç»å·ã€åç§°ã€ä½œè€…ã€è—ç»ã€å·æ•°ã€ç›®å½•æ¡ç›®æ•°ï¼‰
  2. ç»ˆç«¯è¾“å‡ºæ‘˜è¦ç»Ÿè®¡

ç”¨æ³•ï¼š
    python tools/export_catalog.py              # é»˜è®¤å¯¼å‡º
    python tools/export_catalog.py --xlsx       # åŒæ—¶ç”Ÿæˆ xlsxï¼ˆéœ€è¦ openpyxlï¼‰
"""

import csv
import os
import sqlite3
import time
import argparse
from pathlib import Path

# é…ç½®
ETL_DIR = Path(__file__).resolve().parent.parent
OUTPUT_DIR = ETL_DIR / "output"
CANON_DB = OUTPUT_DIR / "cbeta.db"
NAV_DB = OUTPUT_DIR / "cbeta_nav.db"


def export_catalog():
    """å¯¼å‡ºç»¼åˆç›®å½•"""
    start = time.time()

    if not CANON_DB.exists():
        print(f"âŒ æ‰¾ä¸åˆ° cbeta.db: {CANON_DB}")
        return

    conn = sqlite3.connect(str(CANON_DB))
    conn.row_factory = sqlite3.Row

    # è·å– catalog è¡¨ç»“æ„
    cols = [r[1] for r in conn.execute("PRAGMA table_info(catalog)").fetchall()]
    print(f"ğŸ“‹ catalog å­—æ®µ: {cols}")
    print()

    parser = argparse.ArgumentParser(description="ç»¼åˆç›®å½•å¯¼å‡ºå·¥å…·")
    parser.add_argument("--fast", action="store_true", help="å¿«é€Ÿæ¨¡å¼ï¼ˆè·³è¿‡å­—æ•°ç»Ÿè®¡ï¼Œç¬é—´å®Œæˆï¼‰")
    parser.add_argument("--xlsx", action="store_true", help="åŒæ—¶ç”Ÿæˆ xlsxï¼ˆéœ€è¦ openpyxlï¼‰")
    args = parser.parse_args()

    # ä¸»æŸ¥è¯¢
    if args.fast:
        print("ğŸš€ å¿«é€Ÿæ¨¡å¼ï¼šè·³è¿‡å…¨åº“å­—æ•°ç»Ÿè®¡...")
        query = """
            SELECT 
                sutra_id, canon, volume, title, author, total_juan, category,
                (SELECT COUNT(*) FROM content WHERE content.sutra_id = catalog.sutra_id) AS juan_count_db,
                0 AS total_chars
            FROM catalog
            ORDER BY sutra_id
        """
    else:
        # full scan aggregation (slow on 4.7GB+ DB)
        query = """
            SELECT 
                c.sutra_id,
                c.canon,
                c.volume,
                c.title,
                c.author,
                c.total_juan,
                c.category,
                COUNT(DISTINCT ct.juan) AS juan_count_db,
                SUM(LENGTH(ct.plain_text)) AS total_chars
            FROM catalog c
            LEFT JOIN content ct ON c.sutra_id = ct.sutra_id
            GROUP BY c.sutra_id
            ORDER BY c.sutra_id
        """

    print("â³ æŸ¥è¯¢ cbeta.dbï¼ˆå¯èƒ½éœ€è¦å‡ ç§’ï¼‰...")
    rows = conn.execute(query).fetchall()
    print(f"ğŸ“Š æŸ¥åˆ° {len(rows)} æ¡è®°å½•")

    # å¦‚æœæœ‰ cbeta_nav.dbï¼Œé™„åŠ ç›®å½•æ¡ç›®æ•°å’Œéƒ¨ç±»ä¿¡æ¯
    nav_toc_counts = {}
    nav_juan_counts = {}
    nav_bulei_map = {}  # sutra_id -> éƒ¨ç±»å
    if NAV_DB.exists():
        nav_conn = sqlite3.connect(str(NAV_DB))
        print("ğŸ“Š åŠ è½½ cbeta_nav.db æ•°æ®...")
        for r in nav_conn.execute("SELECT sutra_id, COUNT(*) FROM nav_toc GROUP BY sutra_id"):
            nav_toc_counts[r[0]] = r[1]
        for r in nav_conn.execute("SELECT sutra_id, COUNT(*) FROM nav_juan GROUP BY sutra_id"):
            nav_juan_counts[r[0]] = r[1]
        # è¯»å–éƒ¨ç±»æ˜ å°„
        try:
            for r in nav_conn.execute("SELECT sutra_id, bu_lei FROM nav_bulei"):
                nav_bulei_map[r[0]] = r[1]
            print(f"  nav_bulei: {len(nav_bulei_map)} ç»æœ‰éƒ¨ç±»æ•°æ®")
        except Exception:
            print("  âš ï¸ nav_bulei è¡¨ä¸å­˜åœ¨ï¼Œè·³è¿‡éƒ¨ç±»ï¼ˆè¯·å…ˆè¿è¡Œ etl_bookcase_nav.pyï¼‰")
        nav_conn.close()
        print(f"  nav_toc: {len(nav_toc_counts)} ç»æœ‰ç›®å½•æ•°æ®")
        print(f"  nav_juan: {len(nav_juan_counts)} ç»æœ‰å·ç´¢å¼•æ•°æ®")

    # å†™å…¥ CSV
    csv_path = OUTPUT_DIR / "catalog_full.csv"
    headers = [
        "sutra_id",     # ç»å·
        "bu_lei",       # éƒ¨ç±»ï¼ˆå¦‚ 'é˜¿å«éƒ¨é¡'ï¼‰
        "canon",        # è—ç»ä»£ç ï¼ˆT/X/J ç­‰ï¼‰
        "volume",       # å†Œå·
        "title",        # ç»å
        "author",       # ä½œè€…/è¯‘è€…
        "category",     # æ‰€å±è—ç»ä¸­æ–‡å
        "total_juan",   # å…ƒæ•°æ®å·æ•°
        "juan_count",   # DB å®é™…å·æ•°
        "total_chars",  # æ€»å­—æ•°ï¼ˆçº¯æ–‡æœ¬ï¼‰
        "toc_entries",  # ç›®å½•æ¡ç›®æ•°ï¼ˆæ¥è‡ª cbeta_nav.dbï¼‰
        "nav_juans",    # å·ç´¢å¼•æ•°ï¼ˆæ¥è‡ª cbeta_nav.dbï¼‰
    ]

    # æŒ‰éƒ¨ç±»+ç»å·æ’åº
    rows_with_bulei = []
    for row in rows:
        sid = row["sutra_id"]
        bu_lei = nav_bulei_map.get(sid, "")
        rows_with_bulei.append((bu_lei, row))
    rows_with_bulei.sort(key=lambda x: (x[0] if x[0] else "zzz", x[1]["sutra_id"]))

    with open(str(csv_path), "w", encoding="utf-8-sig", newline="") as f:
        w = csv.writer(f)
        w.writerow(headers)

        for bu_lei, row in rows_with_bulei:
            sid = row["sutra_id"]
            w.writerow([
                sid,
                bu_lei,
                row["canon"] or "",
                row["volume"] or "",
                row["title"] or "",
                row["author"] or "",
                row["category"] or "",
                row["total_juan"] or "",
                row["juan_count_db"],
                row["total_chars"] or 0,
                nav_toc_counts.get(sid, 0),
                nav_juan_counts.get(sid, 0),
            ])

    conn.close()
    elapsed = time.time() - start

    # ç»Ÿè®¡æ‘˜è¦
    print()
    print("=" * 60)
    print(f"âœ… å·²å¯¼å‡º: {csv_path}")
    print(f"ğŸ“Š æ€»ç»å…¸æ•°: {len(rows)}")
    print(f"ğŸ“Š æ€»å·æ•°: {sum(r['juan_count_db'] for r in rows)}")
    total_chars = sum(r['total_chars'] or 0 for r in rows)
    print(f"ğŸ“Š æ€»å­—æ•°: {total_chars:,} ({total_chars/10000:.0f} ä¸‡å­—)")
    print(f"ğŸ’¾ æ–‡ä»¶å¤§å°: {csv_path.stat().st_size / 1024:.0f} KB")
    print(f"â±ï¸ è€—æ—¶: {elapsed:.1f} ç§’")

    # æŒ‰éƒ¨ç±»æ±‡æ€»
    if nav_bulei_map:
        print()
        print("ğŸ“š å„éƒ¨ç±»æ±‡æ€»:")
        print(f"{'éƒ¨ç±»':<20} {'ç»å…¸æ•°':>6} {'å·æ•°':>6} {'ä¸‡å­—':>8}")
        print("-" * 45)
        bulei_stats = {}
        for row in rows:
            bl = nav_bulei_map.get(row["sutra_id"], "(æœªåˆ†ç±»)")
            if bl not in bulei_stats:
                bulei_stats[bl] = {"count": 0, "juans": 0, "chars": 0}
            bulei_stats[bl]["count"] += 1
            bulei_stats[bl]["juans"] += row["juan_count_db"]
            bulei_stats[bl]["chars"] += row["total_chars"] or 0

        for bl, stats in sorted(bulei_stats.items(), key=lambda x: -x[1]["count"]):
            print(f"  {bl:<18} {stats['count']:>6} {stats['juans']:>6} {stats['chars']/10000:>8.0f}")

    # æŒ‰è—ç»æ±‡æ€»
    print()
    print("ğŸ“š å„è—ç»æ±‡æ€»:")
    print(f"{'è—ç»':<20} {'ç»å…¸æ•°':>6} {'å·æ•°':>6} {'ä¸‡å­—':>8}")
    print("-" * 45)
    canon_stats = {}
    for row in rows:
        cat = row["category"] or "(æœªåˆ†ç±»)"
        if cat not in canon_stats:
            canon_stats[cat] = {"count": 0, "juans": 0, "chars": 0}
        canon_stats[cat]["count"] += 1
        canon_stats[cat]["juans"] += row["juan_count_db"]
        canon_stats[cat]["chars"] += row["total_chars"] or 0

    for cat, stats in sorted(canon_stats.items(), key=lambda x: -x[1]["count"]):
        print(f"  {cat:<18} {stats['count']:>6} {stats['juans']:>6} {stats['chars']/10000:>8.0f}")


if __name__ == "__main__":
    export_catalog()
