#!/usr/bin/env python3
"""
ä» bulei_catalog_slim.md æå–ç»â†’ç–å¯¹åº”å…³ç³» V10ï¼ˆç»¼åˆä¿®å¤ç‰ˆï¼‰ã€‚

- æ ˆå¼æ ‘è§£æï¼šè‡ªåŠ¨å¤„ç†ç¼©è¿›å±‚çº§
- ä¸¥æ ¼ classify_item åˆ†ç±»éš”ç¦»ï¼ˆæœç»å±‚çº§å€’ç½®ï¼‰
- è¯„åˆ†å– maxï¼ˆæœç» if-elif çŸ­è·¯å¯¼è‡´çš„ä¼˜å…ˆçº§é”™è¯¯ï¼‰
- get_core_name æ”¯æŒè¿ç»­å¤šå‰ç¼€/åç¼€å‰¥ç¦»
- ã€V10ã€‘æ³¨ç–ä¹‹é—´å…¨ç§°åŒ¹é…ï¼šåŒç»„å†…è‹¥æ³¨ç– A çš„å…¨ç§°å‡ºç°åœ¨
  æ³¨ç– B çš„æ ‡é¢˜ä¸­ï¼Œåˆ™é¢å¤–äº§ç”Ÿ Aâ†’B å¯¹åº”å…³ç³»ï¼ˆç–ä¹‹ç–é“¾æ¡ï¼‰
"""
import re
import csv
import sys
from pathlib import Path
from collections import Counter


# ============================================================
# 1. æ–‡çŒ®å­¦åˆ†ç±»è§„åˆ™
# ============================================================

# å¿½ç•¥é¡¹ï¼ˆéç»éç–ï¼‰
IGNORE_KW = [
    'ç¦®æ‡º', 'æ‡ºæ³•', 'å¯¶æ‡º', 'å„€è»Œ', 'è¡Œæ³•', 'å¿µèª¦', 'æ¶ˆç½',
    'ç»ä¾›', 'æ‡ºé¡˜', 'æ—¥èª¦', 'ä¸‰æ˜§è¡Œæ³•', 'ç§‘å„€', 'åˆ†é–€åœ–',
    'æœƒè­¯', 'ç•°æœ¬', 'æˆè¨˜ç¶“', 'éˆ”ç¶“',
]
FORCE_SUTRA_IDS = {'T0226', 'T0840', 'T0841', 'CC0006'}

# æ³¨ç–åç¼€ï¼ˆç”¨äº endswith åŒ¹é…ï¼‰
COMM_SUFFIXES = [
    # é•¿å¤åˆåç¼€ä¼˜å…ˆ
    'ç„ç¾©é‡‹ç±¤', 'ç„ç¾©æ–‡å¥', 'ç–ç¾©æ¼”', 'ç–éˆ”ç„è«‡', 'è¿°æ–‡è´Š',
    'æŒä¸­æ¨è¦', 'äº†ç¾©ç‡ˆ', 'ç­†å‰Šè¨˜', 'è£‚ç¶²ç–', 'é€šç„éˆ”',
    'ç™¼æºæ©Ÿè¦', 'ä¸‰å¾·æŒ‡æ­¸', 'å¦™å®—éˆ”', 'èæŒè¨˜', 'åœ“ä¸­éˆ”',
    'ä¾¿è’™éˆ”', 'é–‹å®—ç¾©è¨˜', 'é–‹å®—ç¾©æ±º', 'éš¨è½ç–æ±º', 'éš¨è½ç–',
    'é ˜è¦éˆ”', 'é¡¯å¹½éˆ”', 'æ¢ç„è¨˜',
    # æ ‡å‡†æ³¨ç–åç¼€
    'ç¾©ç–', 'ç„ç¾©', 'æ–‡å¥', 'è¿°è¨˜', 'è«–ç–', 'é‡‹è«–', 'éŸ³ç¾©',
    'é›†è§£', 'è¦è§£', 'é‡‹ç±¤', 'ç„è´Š', 'ç„è«–', 'éŠæ„', 'æ¸¸æ„',
    'å®—è¦', 'ç¾©è¨˜', 'ç•¥çº‚', 'çº‚è¦', 'ç§‘æ–‡', 'ç§‘è¨»', 'ç§‘æ³¨',
    'ç–éˆ”', 'ç–æ³¨', 'ç–ç§‘', 'ç–è¨˜', 'æ¼”ç¾©', 'ç§‘æ‹¾',
    'å¥è§£', 'é€šç¾©', 'æœƒç¾©', 'ç²¾è§£', 'ç¶¸è²«', 'æœƒè§£',
    'çµ±è«–', 'æ­£çœ¼', 'è§€å¿ƒé‡‹', 'ç•¥è«‡', 'éŸ³é‡‹', 'æ·ºè§£',
    'éƒ¨æ—¨', 'æ¼”å¤', 'ç›´èªª', 'å¿ƒå°ç–', 'è¨‚ç¾©', 'é—¡èªª',
    'å¿ƒé¡', 'è¿‘é‡‹', 'æç¾©', 'å¥é‡‹', 'é¡è§£', 'é›†è¨»',
    'é›†æ³¨', 'ç›´è§£', 'çº‚è¨»', 'çº‚æ³¨', 'æ·è¦', 'çºŒç–',
    'æœƒé‡‹', 'é‡‹è¨˜', 'è£œè¨»', 'è£œæ³¨', 'å®—é€š', 'åˆé‡‹',
    'æ±ºç–‘', 'é‡‡å¾®', 'éŠ·é‡‹', 'å…¥ç–', 'åˆè«–', 'åˆè¨»',
    'åˆæ³¨', 'ç™¼éš±', 'å•è¾¯', 'è®€æ•™è¨˜', 'æ ¼è¨€', 'åˆ¥æŠ„',
    'ç¾©è˜Š', 'å­¸è¨˜', 'ä¿—è©®', 'è­‰ç¾©', 'æœç„', 'ç¶±ç›®',
    'ç•¥ç­–', 'è¿°è´Š', 'å¯¶çªŸ', 'ç…§è§£', 'é †æ­£è¨˜', 'æ–°è¨˜',
    'æ”é‡‹', 'æ±ºæ“‡è¨˜', 'è¡·è«–', 'èå¿ƒè§£', 'æ­£è§€è¨˜', 'åœ–é Œ',
    'åŒç•°é›†', 'é–‹æ±ºè¨˜', 'å»£é‡‹', 'ç•¥è¿°', 'é–‹è’™', 'å¤§æ„',
    'è«–ç¾©', 'æ“Šç¯€', 'å“è§£', 'çŸ¥éŸ³', 'æ­£è¨›', 'æ­£è§£',
    'çŸ³æ³¨', 'éƒ¢èªª', 'æŒ‡æŒ', 'æŒ‡ç–', 'ç­†è¨˜', 'é€šèªª',
    'çº‚é‡‹', 'æ·ºèªª', 'ç•¥èªª', 'æ—¨è´Š', 'æŒ¾è¨»', 'é †ç¡ƒ',
    'åˆæ´¥', 'æ–™ç°¡', 'ç´„æ„', 'è¦é›†', 'è£œéº', 'è´…è¨€',
    'è¦çŸ©', 'è§£ç¾©', 'é‡‹ç¾©', 'é‡‹ç–‘', 'ç°¡è¨»', 'è©•æ—',
    'æ‡¸è«‡', 'æ‡¸ç¤º', 'è©•è¨»', 'è©•æ³¨', 'æ¦‚è«–', 'æç¶±',
    'é‡‹è¦', 'å°è«‡', 'ç›´è«‡', 'è¦è«–', 'æ·»è¶³', 'è²«ç¾©',
    'éš›æ±º', 'é–‹åº¦', 'æ–²è¼ªè§£', 'è«‹ç›Šèªª', 'ç¶“é',
    'æ·ºè¨»', 'æ·ºæ³¨', 'ç•¥è¨»', 'ç•¥æ³¨', 'å½™çº‚', 'å¦‚æ˜¯ç¶“ç¾©',
    'å¦‚æ˜¯è§£', 'æ˜“è§£', 'å£è¨£', 'ç ´ç©ºè«–', 'ç‚ºç‚ºç« ',
    'è†šèªª', 'æ¢ç®‡', 'æœƒæœ¬', 'ç§å¿—', 'æ¸¸åˆƒ', 'ç„¡æˆ‘ç–',
    'æ‰¶æ–°è«–', 'ç´„è«–', 'æŒ‡å—', 'é€šè´Š', 'ç„ç–', 'ç•¥ç–',
    'æ³¨è§£', 'è¨»è§£', 'æ³¨é‡‹', 'è«–è¨˜', 'ç§è¨˜',
    # çŸ­åç¼€æ”¾æœ€åï¼ˆåª endswith åŒ¹é…ï¼‰
    'ç–', 'éˆ”', 'æŠ„', 'è¨˜', 'è§£', 'è¨»', 'æ³¨', 'è¬›', 'è¿°',
    'è´Š', 'è®š', 'ç§‘', 'é‡‹',
]


def classify_item(title, item_id=''):
    """
    å¯¹å•æ¡ç›®è¿›è¡Œæ–‡çŒ®å­¦åˆ†ç±»ã€‚
    è¿”å›: 'original', 'commentary', 'ignore'
    """
    # å¼ºåˆ¶åˆ†ç±»
    if item_id in FORCE_SUTRA_IDS:
        return 'original'

    # å¿½ç•¥é¡¹
    for kw in IGNORE_KW:
        if kw in title:
            return 'ignore'

    # é¢„å¤„ç†ï¼šå»æ‰æœ«å°¾å·æ•°
    clean = re.sub(r'[ï¼ˆ(].*?[ï¼‰)]', '', title)  # å»æ‹¬å·å†…å®¹
    clean = re.sub(r'(å·[ä¸Šä¸­ä¸‹ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾\d]+)$', '', clean).strip()

    # ã€Œé Œã€ç»“å°¾ â†’ åŸè®º
    if clean.endswith('é Œ'):
        return 'original'

    # åç¼€åŒ¹é…ï¼ˆé•¿åç¼€ä¼˜å…ˆï¼‰
    for suf in COMM_SUFFIXES:
        if clean.endswith(suf):
            return 'commentary'

    # ç»/å¾‹/è®º/æˆ’æœ¬ ç»“å°¾ â†’ åŸå…¸
    if re.search(r'(ç¶“|å¾‹|è«–|æˆ’æœ¬|ç¾¯ç£¨|æ³•é–€ç¶“)$', clean):
        return 'original'

    # å…œåº•ï¼šæ ‡é¢˜ä¸­é—´å«æ³¨ç–å…³é”®è¯
    mid_kw = [kw for kw in COMM_SUFFIXES if len(kw) >= 2]
    for kw in mid_kw:
        if kw in clean:
            return 'commentary'

    return 'original'


# ============================================================
# 2. æ ¸å¿ƒåæå–ä¸åŒ¹é…
# ============================================================

def get_core_name(title):
    """æå–ç»åæ ¸å¿ƒéƒ¨åˆ†ï¼Œç”¨äºåŒ¹é…"""
    t = re.sub(r'^(ä½›èªª|å¤§ä¹˜|è–ä½›æ¯|ä½›æ¯|å¤§æ–¹å»£ä½›|å¤§æ–¹å»£|å¾¡æ³¨|æ–°è­¯|ä½›å‚|å¾¡è¨»)', '', title)
    t = re.sub(r'(æ³¢ç¾…èœœå¤šç¶“|æ³¢ç¾…èœœç¶“|æ³¢ç¾…èœœå¤š|æ³¢ç¾…èœœ|ç¶“|å¾‹|è«–|æœ¬é¡˜|åŠŸå¾·|å¤§æ˜å‘ª)$', '', t)
    return t.strip()


def match_commentary_to_sutras(c_title, sutras):
    """
    ä¸ºä¸€éƒ¨æ³¨ç–åŒ¹é…æœ€åˆé€‚çš„åŸç»ã€‚
    ç­–ç•¥: å¤šç§åŒ¹é…æ–¹å¼å– max åˆ† â†’ å–æœ€é«˜åˆ†
    """
    if len(sutras) == 1:
        return sutras

    c_core = get_core_name(c_title)
    scored = []

    for sid, stitle in sutras:
        s_core = get_core_name(stitle)
        candidates = []  # æ”¶é›†å„åŒ¹é…ç­–ç•¥çš„å¾—åˆ†ï¼Œå–æœ€é«˜

        # ç­–ç•¥ 1: ç»åå…¨ç§°åœ¨æ³¨ç–æ ‡é¢˜ä¸­ï¼ˆæœ€ç²¾ç¡®ï¼Œæƒé‡æœ€é«˜ï¼‰
        if stitle in c_title:
            candidates.append(len(stitle) * 10)
        # ç­–ç•¥ 2: ç»åæ ¸å¿ƒåœ¨æ³¨ç–æ ‡é¢˜ä¸­
        if len(s_core) >= 2 and s_core in c_title:
            candidates.append(len(s_core) * 10)
        # ç­–ç•¥ 3: æ³¨ç–æ ¸å¿ƒåœ¨ç»åä¸­
        if len(c_core) >= 2 and c_core in stitle:
            candidates.append(len(c_core) * 8)
        # ç­–ç•¥ 4: é€å­—æˆªæ–­åŒ¹é…ï¼ˆè‡³å°‘éœ€è¦åŒ¹é…å‰ 3 ä¸ªå­—ï¼‰
        core = stitle.replace('ä½›èªª', '').replace('ä½›è¯´', '')
        for ln in range(min(len(core), 12), 2, -1):
            if core[:ln] in c_title:
                candidates.append(ln)
                break

        score = max(candidates) if candidates else 0
        if score > 0:
            scored.append((score, sid, stitle))

    # å¦‚æœå®Œå…¨æ²¡æœ‰åŒ¹é…åˆ†æ•°ï¼Œç»å¯¹ä¸èƒ½"ççŒœ"ï¼Œç›´æ¥æŠ›å¼ƒ
    if not scored:
        return []

    # å–æœ€é«˜åˆ†çš„åŒ¹é…é¡¹
    scored.sort(reverse=True)
    top = scored[0][0]
    return [(s[1], s[2]) for s in scored if s[0] == top]


# ============================================================
# 3. æ ˆå¼æ ‘è§£æï¼ˆæ ¸å¿ƒï¼‰
# ============================================================

ITEM_RE = re.compile(r'`([A-Za-z0-9]+)`\s+(.+)')
BOLD_RE = re.compile(r'^\s*-\s+\*\*(.+?)\*\*\s*$')


def parse_and_extract(filepath):
    """
    æ ˆå¼è§£æ + classify_item ä¸¥æ ¼åˆ†ç±»ã€‚

    é‡åˆ° ğŸ“– è¡Œ â†’ å‹æ ˆæ–° group
    é‡åˆ° **bold** è¡Œ â†’ å‹æ ˆç»´æŠ¤ç¼©è¿›å±‚çº§ï¼ˆä¸å½±å“åˆ†ç±»å†³ç­–ï¼‰
    é‡åˆ° `ID` è¡Œ â†’ ç”± classify_item å†³å®šå½’ç±»
    ç¼©è¿›å˜æµ… â†’ è‡ªåŠ¨å¼¹å‡º
    """
    with open(filepath, 'r', encoding='utf-8') as f:
        lines = f.readlines()

    groups = []
    # æ ˆå…ƒç´ : (ç¼©è¿›, group)
    stack = []

    for line in lines:
        if not line.strip():
            continue

        expanded = line.replace('\t', '    ')
        indent = len(expanded) - len(expanded.lstrip())
        content = line.strip()

        # å¼¹å‡ºç¼©è¿› >= å½“å‰è¡Œçš„æ ˆå…ƒç´ 
        while stack and stack[-1][0] >= indent:
            stack.pop()

        if 'ğŸ“–' in content:
            # æ–°çš„ç»ç–ç»„
            new_group = {
                'title': content,
                'originals': [],
                'commentaries': [],
            }
            groups.append(new_group)
            stack.append((indent, new_group))
        else:
            # ç²—ä½“å­åŒºæ ‡é¢˜ â†’ ä»…ç”¨äºç»´æŠ¤ç¼©è¿›å±‚çº§
            bold_match = BOLD_RE.match(line)
            if bold_match and stack:
                parent_group = stack[-1][1]
                stack.append((indent, parent_group))
                continue

            # æ£€æŸ¥æ˜¯å¦ä¸ºæ¡ç›®
            item_match = ITEM_RE.search(content)
            if item_match and stack:
                item_id = item_match.group(1)
                item_title = item_match.group(2).strip()
                current_group = stack[-1][1]

                # ä¸¥æ ¼æ‰§è¡Œ classify_item åˆ†ç±»éš”ç¦»
                cls = classify_item(item_title, item_id)
                if cls == 'ignore':
                    continue
                if cls == 'original':
                    current_group['originals'].append((item_id, item_title))
                elif cls == 'commentary':
                    current_group['commentaries'].append((item_id, item_title))

    return groups


# ============================================================
# 4. ç”ŸæˆåŒ¹é…å…³ç³»
# ============================================================

def extract_relations(groups):
    """ä»ç»„ä¸­æå– ç»â†’ç– å¯¹åº”ï¼Œå¹¶è¡¥å……ç–ä¹‹ç–å…³ç³»"""
    results = []

    for group in groups:
        originals = group['originals']
        comms = group['commentaries']

        if not originals or not comms:
            continue

        # ç¬¬ä¸€è½®ï¼šç» â†’ ç– åŒ¹é…
        for c_id, c_title in comms:
            matched = match_commentary_to_sutras(c_title, originals)
            for o_id, o_title in matched:
                results.append((o_id, o_title, c_id, c_title))

        # ç¬¬äºŒè½®ï¼šç– â†’ ç– å…¨ç§°åŒ¹é…ï¼ˆç–ä¹‹ç–é“¾æ¡ï¼‰
        # å¦‚æœæ³¨ç– A çš„å…¨ç§°å‡ºç°åœ¨æ³¨ç– B çš„æ ‡é¢˜ä¸­ï¼Œåˆ™ A æ˜¯ B çš„ base text
        if len(comms) >= 2:
            for a_id, a_title in comms:
                for b_id, b_title in comms:
                    if a_id == b_id:
                        continue
                    # A çš„å…¨ç§°å¿…é¡»å‡ºç°åœ¨ B çš„æ ‡é¢˜ä¸­ï¼Œ
                    # ä¸” B çš„æ ‡é¢˜è¦æ¯” A é•¿ï¼ˆB æ˜¯å¯¹ A çš„è¿›ä¸€æ­¥æ³¨é‡Šï¼‰
                    if a_title in b_title and len(b_title) > len(a_title):
                        results.append((a_id, a_title, b_id, b_title))
                    else:
                        # å®¹é”™ï¼šA æ ‡é¢˜å¯èƒ½æœ‰å‰ç¼€ï¼ˆä½›èªª/å¤§ä¹˜ç­‰ï¼‰ï¼Œå‰¥ç¦»åå†è¯•
                        a_stripped = re.sub(
                            r'^(ä½›èªª|å¤§ä¹˜|è–ä½›æ¯|ä½›æ¯|å¤§æ–¹å»£ä½›|å¤§æ–¹å»£|å¾¡æ³¨|æ–°è­¯|ä½›å‚|å¾¡è¨»)',
                            '', a_title)
                        if a_stripped != a_title and a_stripped in b_title and len(b_title) > len(a_stripped):
                            results.append((a_id, a_title, b_id, b_title))

    # å»é‡ + è¿‡æ»¤å·²çŸ¥è¯¯é…
    seen = set()
    unique = []
    for r in results:
        key = (r[0], r[2])
        if key in seen:
            continue
        # è¿‡æ»¤ï¼šåŒåå¼‚ç‰ˆäº’æŒ‡ï¼ˆå¦‚ T1567â†”K1482 éƒ½å«ã€Œå¤§ä¹˜ä¸­è§€é‡‹è«–ã€ï¼‰
        if r[1] == r[3]:
            continue
        # è¿‡æ»¤ï¼šæ”å¤§ä¹˜è«–é‡‹ â†’ æ”å¤§ä¹˜è«–é‡‹è«–ï¼ˆé‡‹ä¸æ˜¯é‡‹è«–çš„ base textï¼‰
        if r[1].endswith('æ”å¤§ä¹˜è«–é‡‹') and r[3] == 'æ”å¤§ä¹˜è«–é‡‹è«–':
            continue
        seen.add(key)
        unique.append(r)

    return unique


# ============================================================
# 5. ä¸»å‡½æ•°
# ============================================================

def main():
    base = Path(__file__).parent
    catalog = base / 'bulei_catalog_slim.md'
    output = base / 'sutra_commentary_pairs.csv'

    if not catalog.exists():
        print(f"âŒ æ‰¾ä¸åˆ° {catalog}")
        sys.exit(1)

    print(f"ğŸ“„ è§£æ: {catalog}")
    groups = parse_and_extract(catalog)

    valid_groups = [g for g in groups if g['originals'] and g['commentaries']]
    print(f"ğŸ“– æ‰¾åˆ° {len(valid_groups)} ä¸ªæœ‰æ•ˆç»ç–ç»„")

    for g in valid_groups:
        ns, nc = len(g['originals']), len(g['commentaries'])
        flag = ' âš ï¸' if ns > 10 else ''
        # åªæ‰“å°å‰ 65 ä¸ªå­—ç¬¦ä»¥å…è¿‡é•¿
        print(f"  ç»{ns:3d} ç–{nc:3d}{flag} | {g['title'][:65]}")

    relations = extract_relations(groups)

    with open(output, 'w', encoding='utf-8-sig', newline='') as f:
        w = csv.writer(f)
        w.writerow(['sutra_id', 'sutra_title', 'commentary_id', 'commentary_title'])
        w.writerows(relations)

    # ç»Ÿè®¡
    s_ids = set(r[0] for r in relations)
    c_ids = set(r[2] for r in relations)
    c_count = Counter(r[2] for r in relations)
    print(f"\n{'='*50}")
    print(f"âœ… å…± {len(relations)} å¯¹ç»â†’ç–")
    print(f"   åŸç»/è®º: {len(s_ids)} éƒ¨, æ³¨ç–: {len(c_ids)} éƒ¨")

    dist = Counter(c_count.values())
    print(f"\næ³¨ç–å¯¹åº”ç»æ•°åˆ†å¸ƒ:")
    for n in sorted(dist.keys()):
        print(f"  {n:2d}éƒ¨ç»: {dist[n]:3d}éƒ¨æ³¨ç–")

    anomalies = [(cid, cnt) for cid, cnt in c_count.items() if cnt > 8]
    if anomalies:
        print(f"\nâš ï¸  å¯¹åº” >8 éƒ¨ç» ({len(anomalies)} éƒ¨):")
        for cid, cnt in sorted(anomalies, key=lambda x: -x[1])[:10]:
            ct = [r[3] for r in relations if r[2] == cid][0][:35]
            sids = [r[0] for r in relations if r[2] == cid][:5]
            print(f"  {cid:8s} {ct:35s} â†’ {cnt}éƒ¨: {', '.join(sids)}")

    print(f"\nğŸ’¾ è¾“å‡º: {output}")


if __name__ == '__main__':
    main()
